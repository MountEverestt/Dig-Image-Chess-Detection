{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vYtrwN1rIfE2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction Before Running\n",
        "We have 2 pre-trained models that will be used in our project.\n",
        "Here is the path you can get\n",
        "\n",
        "\n",
        "1. YOLO Model :\n",
        "\n",
        "https://drive.google.com/file/d/1wL-OiTJXFwb4BUTvV6JZOSXcgP5wWAOZ/view?usp=drive_link\n",
        "\n",
        "\n",
        "2. U-Net Model :\n",
        "\n",
        "https://drive.google.com/file/d/1dFIb0wo3yMqmd9kIzyLGfPU5NvetYLyN/view?usp=sharing\n",
        "\n",
        "\n",
        "\n",
        " ## After discovering the models, please use google drive to mount and insert the path into the variable model_path for both U-Net and YOLO Model."
      ],
      "metadata": {
        "id": "AxFCrnKQIRgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python-headless matplotlib numpy mediapipe --quiet"
      ],
      "metadata": {
        "id": "KAlpHFeNE2zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vab13YKWGQ-O",
        "outputId": "b98ce7d8-903a-43dc-a726-b8e292ea56bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Chess Move Detection Pipeline from Video\n",
        "=========================================\n",
        "A complete computer vision pipeline for detecting chess moves from video footage.\n",
        "\n",
        "This module provides functions to:\n",
        "1. Extract and filter video frames (removing frames with hands)\n",
        "2. Detect chessboard corners using a pre-trained U-Net model\n",
        "3. Determine board orientation using OCR + VLM reasoning\n",
        "4. Detect chess pieces using a pre-trained YOLO model\n",
        "5. Track board state changes and generate PGN notation\n",
        "\n",
        "Prerequisites:\n",
        "- Pre-trained YOLO model for chess piece detection (loaded externally)\n",
        "- Pre-trained U-Net model for corner detection (loaded externally)\n",
        "- MediaPipe for hand detection\n",
        "- OpenCV, NumPy, Matplotlib for image processing and visualization\n",
        "\n",
        "Author: Chess Vision Pipeline\n",
        "Version: 1.0\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle, Circle, FancyArrow\n",
        "from matplotlib.lines import Line2D\n",
        "import mediapipe as mp\n",
        "from typing import List, Tuple, Dict, Optional, Any, Union\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "import base64\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "SpEQ41wPnmG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding detail"
      ],
      "metadata": {
        "id": "e6NaeD5TIiap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_center_square(frame: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Crop the largest possible square from the center of the frame.\n",
        "\n",
        "    This removes black bars at the top/bottom (or left/right) by\n",
        "    taking a width x width crop centered in the image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame in BGR format.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Center-cropped square frame.\n",
        "    \"\"\"\n",
        "    h, w = frame.shape[:2]\n",
        "\n",
        "    # side length of the square: use the smaller dimension\n",
        "    side = min(h, w)\n",
        "\n",
        "    # top-left corner of the crop\n",
        "    y1 = (h - side) // 2\n",
        "    x1 = (w - side) // 2\n",
        "\n",
        "    y2 = y1 + side\n",
        "    x2 = x1 + side\n",
        "\n",
        "    cropped = frame[y1:y2, x1:x2]\n",
        "    return cropped\n",
        "\n",
        "def pad_frame_for_unet(\n",
        "    frame: np.ndarray,\n",
        "    pad_ratio: float = 0.5\n",
        ") -> Tuple[np.ndarray, Tuple[int, int]]:\n",
        "    \"\"\"\n",
        "    Pad a (square) frame with a black border on all sides before\n",
        "    sending it to U-Net.\n",
        "\n",
        "    pad_ratio = 0.5  => pad width/2 (and height/2) on each side,\n",
        "    so final size = 2 * side.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Original BGR frame (already cropped to board region).\n",
        "    pad_ratio : float\n",
        "        Fraction of the original side length to pad on each side.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[np.ndarray, Tuple[int, int]]\n",
        "        - padded_frame: new image with black border.\n",
        "        - (offset_x, offset_y): top-left corner of the original\n",
        "          frame inside the padded image.\n",
        "    \"\"\"\n",
        "    h, w = frame.shape[:2]\n",
        "    # assume square; if not, use the smaller dimension\n",
        "    side = min(h, w)\n",
        "\n",
        "    pad = int(side * pad_ratio)\n",
        "    new_side = side + 2 * pad\n",
        "\n",
        "    # create black canvas\n",
        "    padded = np.zeros((new_side, new_side, 3), dtype=frame.dtype)\n",
        "\n",
        "    # put original frame in the center\n",
        "    y1 = pad\n",
        "    x1 = pad\n",
        "    y2 = y1 + side\n",
        "    x2 = x1 + side\n",
        "\n",
        "    # if frame isn't exactly square, just crop the center square part\n",
        "    frame_square = frame[0:side, 0:side]\n",
        "    padded[y1:y2, x1:x2] = frame_square\n",
        "\n",
        "    return padded, (x1, y1)\n",
        "\n",
        "# Handle the symbol \"+\"\n",
        "def _square_to_coords(square: str) -> Tuple[int, int]:\n",
        "    \"\"\"Convert algebraic square like 'e4' to (file, rank) = (0..7, 0..7).\"\"\"\n",
        "    file_idx = ord(square[0]) - ord('a')       # a -> 0, ..., h -> 7\n",
        "    rank_idx = int(square[1]) - 1              # '1' -> 0, ..., '8' -> 7\n",
        "    return file_idx, rank_idx\n",
        "\n",
        "\n",
        "def _coords_to_square(file_idx: int, rank_idx: int) -> str:\n",
        "    \"\"\"Convert (file, rank) back to algebraic notation.\"\"\"\n",
        "    return FILES[file_idx] + str(rank_idx + 1)\n",
        "\n",
        "\n",
        "def _can_piece_attack(\n",
        "    piece: str,\n",
        "    from_square: str,\n",
        "    to_square: str,\n",
        "    board: Dict[str, str]\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Check if a single piece on from_square can attack to_square,\n",
        "    taking blocking pieces into account for sliding pieces.\n",
        "    \"\"\"\n",
        "    if from_square == to_square:\n",
        "        return False\n",
        "\n",
        "    piece_type = piece.upper()\n",
        "    from_file, from_rank = _square_to_coords(from_square)\n",
        "    to_file, to_rank = _square_to_coords(to_square)\n",
        "\n",
        "    dx = to_file - from_file\n",
        "    dy = to_rank - from_rank\n",
        "\n",
        "    # Knight\n",
        "    if piece_type == 'N':\n",
        "        return (abs(dx), abs(dy)) in [(1, 2), (2, 1)]\n",
        "\n",
        "    # King\n",
        "    if piece_type == 'K':\n",
        "        return max(abs(dx), abs(dy)) == 1\n",
        "\n",
        "    # Pawn (only capture directions matter for check)\n",
        "    if piece_type == 'P':\n",
        "        direction = 1 if piece.isupper() else -1  # white up, black down\n",
        "        return dy == direction and abs(dx) == 1\n",
        "\n",
        "    # Sliding pieces: Bishop / Rook / Queen\n",
        "    if piece_type in ('B', 'R', 'Q'):\n",
        "        # Movement pattern check\n",
        "        if piece_type == 'B' and (abs(dx) != abs(dy) or dx == 0):\n",
        "            return False\n",
        "        if piece_type == 'R' and not ((dx == 0) ^ (dy == 0)):  # exactly one nonzero\n",
        "            return False\n",
        "        if piece_type == 'Q' and not (\n",
        "            (abs(dx) == abs(dy) and dx != 0) or  # diagonal\n",
        "            ((dx == 0) ^ (dy == 0))              # straight\n",
        "        ):\n",
        "            return False\n",
        "\n",
        "        # Step direction\n",
        "        step_x = 0 if dx == 0 else (1 if dx > 0 else -1)\n",
        "        step_y = 0 if dy == 0 else (1 if dy > 0 else -1)\n",
        "\n",
        "        # Walk along the ray and ensure no blocking pieces\n",
        "        x = from_file + step_x\n",
        "        y = from_rank + step_y\n",
        "        while (x, y) != (to_file, to_rank):\n",
        "            sq = _coords_to_square(x, y)\n",
        "            if sq in board:          # any piece blocks the line\n",
        "                return False\n",
        "            x += step_x\n",
        "            y += step_y\n",
        "\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def is_square_attacked(\n",
        "    board: Dict[str, str],\n",
        "    target_square: str,\n",
        "    by_white: bool\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Return True if target_square is attacked by the given side.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board : Dict[str, str]\n",
        "        Board state (square -> piece code).\n",
        "    target_square : str\n",
        "        Square to test (e.g. 'e4').\n",
        "    by_white : bool\n",
        "        True if we check attacks by white pieces, False for black.\n",
        "    \"\"\"\n",
        "    for square, piece in board.items():\n",
        "        if piece.isupper() != by_white:\n",
        "            continue  # piece belongs to the other side\n",
        "        if _can_piece_attack(piece, square, target_square, board):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def compute_piece_center_with_rotation(\n",
        "    x1: int, y1: int, x2: int, y2: int, rotation_deg: int\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Compute the detection center, biased toward the 'bottom' of the piece\n",
        "    relative to the board orientation.\n",
        "\n",
        "    rotation_deg meaning (same as compute_board_grid):\n",
        "      - 0   : White at BOTTOM of image  (bottom = +y direction)\n",
        "      - 90  : White at RIGHT  of image  (bottom = +x direction)\n",
        "      - 180 : White at TOP    of image  (bottom = -y direction)\n",
        "      - 270 : White at LEFT   of image  (bottom = -x direction)\n",
        "    \"\"\"\n",
        "\n",
        "    # default geometric center\n",
        "    cx = (x1 + x2) / 2.0\n",
        "    cy = (y1 + y2) / 2.0\n",
        "\n",
        "    top_y    = max(y1, y2)\n",
        "    bottom_y = min(y1, y2)\n",
        "    left_x   = min(x1, x2)\n",
        "    right_x  = max(x1, x2)\n",
        "\n",
        "    # weight toward \"bottom\" side of the piece\n",
        "    # alpha > 0.5 means closer to bottom\n",
        "    alpha_bottom = 0.75\n",
        "    alpha_top    = 1-alpha_bottom\n",
        "    # cy = alpha_bottom * top_y + alpha_top * bottom_y\n",
        "    if rotation_deg == 0:\n",
        "        # bottom of board = image bottom  (+y)\n",
        "        cy = alpha_top * top_y + alpha_bottom * bottom_y\n",
        "\n",
        "    elif rotation_deg == 180:\n",
        "        # bottom of board = image TOP (-y)\n",
        "        # swap weights so we go toward smaller y\n",
        "        cy = alpha_bottom * top_y + alpha_top * bottom_y\n",
        "\n",
        "    elif rotation_deg == 90:\n",
        "        # bottom of board = image RIGHT (+x)\n",
        "        cx = alpha_top * left_x + alpha_bottom * right_x\n",
        "\n",
        "\n",
        "    elif rotation_deg == 270:\n",
        "        # bottom of board = image LEFT (-x)\n",
        "        cx = alpha_bottom * left_x + alpha_top * right_x\n",
        "\n",
        "\n",
        "\n",
        "    # if rotation is something else, just keep geometric center\n",
        "\n",
        "    return cx, cy\n",
        "def sharpen_laplacian(img, amount: float = 1.0):\n",
        "    # Laplacian edge map\n",
        "    lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
        "\n",
        "    # Sharpen: original - amount * laplacian\n",
        "    sharp = cv2.addWeighted(img.astype(np.float64), 1.0,\n",
        "                            -lap, amount, 0)\n",
        "\n",
        "    return np.clip(sharp, 0, 255).astype(np.uint8)\n",
        "\n",
        "def sharpen_ultra(img):\n",
        "    # Step 1 — Unsharp mask\n",
        "    blur = cv2.GaussianBlur(img, (0, 0), sigmaX=1.0)\n",
        "    unsharp = cv2.addWeighted(img, 1.8, blur, -0.8, 0)\n",
        "\n",
        "    # Step 2 — High-pass edges\n",
        "    kernel = np.array([\n",
        "        [-1, -1, -1],\n",
        "        [-1,  8, -1],\n",
        "        [-1, -1, -1]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    edges = cv2.filter2D(img, -1, kernel)\n",
        "\n",
        "    # Step 3 — Blend edges into unsharp image\n",
        "    final = cv2.addWeighted(unsharp, 1.0, edges, 0.6, 0)\n",
        "\n",
        "    return final\n",
        "\n"
      ],
      "metadata": {
        "id": "DJL5ciwMVFUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-NET Architecture"
      ],
      "metadata": {
        "id": "vYtrwN1rIfE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -------------------------------\n",
        "# U-NET ARCHITECTURE USED FOR TRAINING\n",
        "# -------------------------------\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=1, features=[64,128,256,512]):\n",
        "        super().__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        prev = in_ch\n",
        "\n",
        "        for f in features:\n",
        "            self.downs.append(DoubleConv(prev, f))\n",
        "            prev = f\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.bottleneck = DoubleConv(prev, prev*2)\n",
        "        prev = prev*2\n",
        "\n",
        "        for f in reversed(features):\n",
        "            self.ups.append(nn.ConvTranspose2d(prev, f, 2, 2))\n",
        "            self.ups.append(DoubleConv(prev, f))\n",
        "            prev = f\n",
        "\n",
        "        self.final_conv = nn.Conv2d(prev, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        out = x\n",
        "\n",
        "        for d in self.downs:\n",
        "            out = d(out)\n",
        "            skips.append(out)\n",
        "            out = self.pool(out)\n",
        "\n",
        "        out = self.bottleneck(out)\n",
        "\n",
        "        for i in range(0, len(self.ups), 2):\n",
        "            out = self.ups[i](out)\n",
        "            skip = skips[-1 - (i//2)]\n",
        "\n",
        "            if out.size()[2:] != skip.size()[2:]:\n",
        "                out = nn.functional.interpolate(out, size=skip.shape[2:])\n",
        "\n",
        "            out = torch.cat((skip, out), dim=1)\n",
        "            out = self.ups[i+1](out)\n",
        "\n",
        "        return torch.sigmoid(self.final_conv(out))\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD MODEL\n",
        "# -------------------------------\n",
        "\n",
        "def load_unet(path):\n",
        "    model = UNet().to(DEVICE)\n",
        "    ckpt = torch.load(path, map_location=DEVICE)\n",
        "    model.load_state_dict(ckpt)\n",
        "    model.eval()\n",
        "    print(\"U-Net Loaded.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# IMAGE ENHANCEMENT METHODS\n",
        "# -------------------------------\n",
        "\n",
        "def apply_sobel(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    sx = cv2.Sobel(gray, cv2.CV_16S, 1, 0, ksize=3)\n",
        "    sy = cv2.Sobel(gray, cv2.CV_16S, 0, 1, ksize=3)\n",
        "    sob = cv2.convertScaleAbs(0.5*sx + 0.5*sy)\n",
        "    sharp = cv2.addWeighted(gray, 1.0, sob, 0.7, 0)\n",
        "    return cv2.cvtColor(sharp, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "def apply_log(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    lap = cv2.Laplacian(blur, cv2.CV_64F, ksize=3)\n",
        "    lap = cv2.convertScaleAbs(lap)\n",
        "    sharp = cv2.addWeighted(gray, 1.2, lap, -0.5, 0)\n",
        "    return cv2.cvtColor(sharp, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# U-NET INFERENCE\n",
        "# -------------------------------\n",
        "\n",
        "def unet_predict(model, img):\n",
        "    h, w = img.shape[:2]\n",
        "    resized = cv2.resize(img, (512,512))\n",
        "    t = torch.tensor(resized/255.0).float().permute(2,0,1).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(t)[0,0].cpu().numpy()\n",
        "\n",
        "    mask512 = (pred > 0.5).astype(np.uint8)\n",
        "    mask = cv2.resize(mask512, (w,h), interpolation=cv2.INTER_NEAREST)\n",
        "    return mask\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# CORNER EXTRACTION\n",
        "# -------------------------------\n",
        "\n",
        "def order_corners(pts):\n",
        "    pts = np.array(pts)\n",
        "    s  = pts.sum(axis=1)\n",
        "    diff = np.diff(pts, axis=1).reshape(-1)\n",
        "\n",
        "    TL = pts[np.argmin(s)]\n",
        "    BR = pts[np.argmax(s)]\n",
        "    TR = pts[np.argmin(diff)]\n",
        "    BL = pts[np.argmax(diff)]\n",
        "\n",
        "    return np.array([TL, TR, BR, BL], float)\n",
        "\n",
        "def extract_corners(mask):\n",
        "    cnts,_ = cv2.findContours(mask.astype(np.uint8)*255,\n",
        "                              cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not cnts:\n",
        "        return None\n",
        "\n",
        "    cnt = max(cnts, key=cv2.contourArea)\n",
        "    peri = cv2.arcLength(cnt, True)\n",
        "    approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
        "\n",
        "    if len(approx) != 4:\n",
        "        rect = cv2.minAreaRect(cnt)\n",
        "        approx = cv2.boxPoints(rect)\n",
        "\n",
        "    return order_corners(approx.reshape(-1,2))\n"
      ],
      "metadata": {
        "id": "348_k1CfXpPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Longer Part"
      ],
      "metadata": {
        "id": "vvCYbLdkIYrQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14tGcW2hnfoV"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONSTANTS AND CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Standard chess piece notation\n",
        "PIECE_SYMBOLS = {\n",
        "    'white-king': 'K', 'white-queen': 'Q', 'white-rook': 'R',\n",
        "    'white-bishop': 'B', 'white-knight': 'N', 'white-pawn': 'P',\n",
        "    'black-king': 'k', 'black-queen': 'q', 'black-rook': 'r',\n",
        "    'black-bishop': 'b', 'balck-knight': 'n', 'black-pawn': 'p'\n",
        "}\n",
        "\n",
        "# Reverse mapping for display\n",
        "PIECE_NAMES = {v: k for k, v in PIECE_SYMBOLS.items()}\n",
        "\n",
        "# Files and ranks for algebraic notation\n",
        "FILES = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
        "RANKS = ['1', '2', '3', '4', '5', '6', '7', '8']\n",
        "\n",
        "# Standard board size for warping\n",
        "DEFAULT_BOARD_SIZE = 800\n",
        "\n",
        "# Visualization colors (BGR format for OpenCV)\n",
        "COLORS = {\n",
        "    'corner': (0, 255, 0),      # Green\n",
        "    'piece': (255, 0, 0),       # Blue\n",
        "    'grid': (128, 128, 128),    # Gray\n",
        "    'move_from': (0, 0, 255),   # Red\n",
        "    'move_to': (0, 255, 0),     # Green\n",
        "    'text': (255, 255, 255),    # White\n",
        "    'white_piece': (255, 255, 200),\n",
        "    'black_piece': (50, 50, 50)\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA CLASSES\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class PieceDetection:\n",
        "    \"\"\"Represents a detected chess piece.\"\"\"\n",
        "    bbox: Tuple[int, int, int, int]  # (x1, y1, x2, y2)\n",
        "    center: Tuple[float, float]       # (cx, cy)\n",
        "    class_id: int\n",
        "    class_name: str\n",
        "    confidence: float\n",
        "    projected_center: Optional[Tuple[float, float]] = None\n",
        "    assigned_square: Optional[str] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BoardState:\n",
        "    \"\"\"Represents the state of the chess board at a given frame.\"\"\"\n",
        "    frame_index: int\n",
        "    pieces: Dict[str, str]  # square -> piece code (e.g., 'e4' -> 'P')\n",
        "    detections: List[PieceDetection] = field(default_factory=list)\n",
        "\n",
        "    def copy(self):\n",
        "        return BoardState(\n",
        "            frame_index=self.frame_index,\n",
        "            pieces=self.pieces.copy(),\n",
        "            detections=self.detections.copy()\n",
        "        )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Move:\n",
        "    \"\"\"Represents a chess move.\"\"\"\n",
        "    from_square: str\n",
        "    to_square: str\n",
        "    piece: str\n",
        "    captured_piece: Optional[str] = None\n",
        "    is_castle: bool = False\n",
        "    castle_side: Optional[str] = None  # 'kingside' or 'queenside'\n",
        "    is_en_passant: bool = False\n",
        "    promotion_piece: Optional[str] = None\n",
        "    is_check: bool = False\n",
        "    is_checkmate: bool = False\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GlobalBoardParameters:\n",
        "    \"\"\"Global parameters computed from the first clean frame.\"\"\"\n",
        "    rotation_degrees: int  # 0, 90, 180, or 270\n",
        "    corners_ordered: np.ndarray  # Shape (4, 2): [TL, TR, BR, BL]\n",
        "    homography_matrix: np.ndarray  # 3x3 homography matrix\n",
        "    board_size: int\n",
        "    grid_centers: np.ndarray  # Shape (64, 2)\n",
        "    square_names: List[str]  # 64 algebraic names\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FRAME EXTRACTION AND FILTERING\n",
        "# ============================================================================\n",
        "\n",
        "def extract_frames_from_video(video_path: str, output_fps: Optional[float] = None) -> List[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Read a video and return a list of frames (BGR np.ndarrays).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    video_path : str\n",
        "        Path to the input video file.\n",
        "    output_fps : float, optional\n",
        "        If specified, resample the video to this frame rate.\n",
        "        If None, extract all frames at original FPS.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[np.ndarray]\n",
        "        List of frames as BGR numpy arrays.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    FileNotFoundError\n",
        "        If the video file cannot be opened.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> frames = extract_frames_from_video(\"chess_game.mp4\", output_fps=2.0)\n",
        "    >>> print(f\"Extracted {len(frames)} frames\")\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        raise FileNotFoundError(f\"Could not open video file: {video_path}\")\n",
        "\n",
        "    # Get video properties\n",
        "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    print(f\"Video properties:\")\n",
        "    print(f\"  - Resolution: {width}x{height}\")\n",
        "    print(f\"  - Original FPS: {original_fps:.2f}\")\n",
        "    print(f\"  - Total frames: {total_frames}\")\n",
        "    print(f\"  - Duration: {total_frames/original_fps:.2f} seconds\")\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    if output_fps is None or output_fps >= original_fps:\n",
        "        # Extract all frames\n",
        "        frame_interval = 1\n",
        "        print(f\"Extracting all frames...\")\n",
        "    else:\n",
        "        # Calculate frame interval for resampling\n",
        "        frame_interval = original_fps / output_fps\n",
        "        print(f\"Resampling to {output_fps} FPS (every {frame_interval:.2f} frames)\")\n",
        "\n",
        "    frame_idx = 0\n",
        "    next_frame_to_extract = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # --- NEW: crop to center square to remove black bars ---\n",
        "        frame = crop_center_square(frame)\n",
        "\n",
        "        if frame_idx >= next_frame_to_extract:\n",
        "            frames.append(frame)\n",
        "            next_frame_to_extract += frame_interval\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Extracted {len(frames)} frames\")\n",
        "    return frames\n",
        "\n",
        "\n",
        "def detect_hands_mediapipe(\n",
        "    frame: np.ndarray,\n",
        "    mp_hands: Any,\n",
        "    min_detection_confidence: float = 0.5\n",
        ") -> Tuple[bool, Any]:\n",
        "    \"\"\"\n",
        "    Use MediaPipe Hands to detect hands in a frame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame in BGR format.\n",
        "    mp_hands : mediapipe.solutions.hands.Hands\n",
        "        Initialized MediaPipe Hands object.\n",
        "    min_detection_confidence : float\n",
        "        Minimum confidence threshold for detection (0.0 to 1.0).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[bool, Any]\n",
        "        - bool: True if at least one hand is detected, False otherwise.\n",
        "        - results: MediaPipe detection results (for visualization).\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> mp_hands_instance = mp.solutions.hands.Hands(min_detection_confidence=0.5)\n",
        "    >>> has_hand, results = detect_hands_mediapipe(frame, mp_hands_instance)\n",
        "    \"\"\"\n",
        "    # Convert BGR to RGB for MediaPipe\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the frame\n",
        "    results = mp_hands.process(frame_rgb)\n",
        "\n",
        "    # Check if any hands were detected\n",
        "    has_hands = results.multi_hand_landmarks is not None\n",
        "\n",
        "    return has_hands, results\n",
        "\n",
        "\n",
        "def filter_frames_no_hands(\n",
        "    frames: List[np.ndarray],\n",
        "    min_detection_confidence: float = 0.2,\n",
        "    visualize_progress: bool = True\n",
        ") -> Tuple[List[np.ndarray], List[int]]:\n",
        "    \"\"\"\n",
        "    Run hand detection on all frames and return frames without hands.\n",
        "\n",
        "    This function filters out frames where a hand is visible (e.g., when\n",
        "    a player is making a move), keeping only \"clean\" frames showing the\n",
        "    stable board state.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frames : List[np.ndarray]\n",
        "        List of video frames in BGR format.\n",
        "    min_detection_confidence : float\n",
        "        Minimum confidence for hand detection.\n",
        "    visualize_progress : bool\n",
        "        If True, print progress information.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[List[np.ndarray], List[int]]\n",
        "        - clean_frames: List of frames without detected hands.\n",
        "        - clean_indices: Corresponding indices in the original frame list.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> clean_frames, indices = filter_frames_no_hands(all_frames)\n",
        "    >>> print(f\"Kept {len(clean_frames)} clean frames out of {len(all_frames)}\")\n",
        "    \"\"\"\n",
        "    # Initialize MediaPipe Hands\n",
        "    mp_hands_module = mp.solutions.hands\n",
        "    hands = mp_hands_module.Hands(\n",
        "        static_image_mode=True,  # Process each frame independently\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=min_detection_confidence,\n",
        "        min_tracking_confidence=0.5\n",
        "    )\n",
        "\n",
        "    clean_frames = []\n",
        "    clean_indices = []\n",
        "    frames_with_hands = 0\n",
        "\n",
        "    if visualize_progress:\n",
        "        print(f\"Filtering {len(frames)} frames for hand presence...\")\n",
        "\n",
        "    for idx, frame in enumerate(frames):\n",
        "        has_hands, _ = detect_hands_mediapipe(frame, hands, min_detection_confidence)\n",
        "\n",
        "        if not has_hands:\n",
        "            clean_frames.append(frame)\n",
        "            clean_indices.append(idx)\n",
        "        else:\n",
        "            frames_with_hands += 1\n",
        "\n",
        "        # Progress update every 50 frames\n",
        "        if visualize_progress and (idx + 1) % 50 == 0:\n",
        "            print(f\"  Processed {idx + 1}/{len(frames)} frames...\")\n",
        "\n",
        "    hands.close()\n",
        "\n",
        "    if visualize_progress:\n",
        "        print(f\"Filtering complete:\")\n",
        "        print(f\"  - Frames with hands (discarded): {frames_with_hands}\")\n",
        "        print(f\"  - Clean frames (kept): {len(clean_frames)}\")\n",
        "        print(f\"  - Retention rate: {len(clean_frames)/len(frames)*100:.1f}%\")\n",
        "\n",
        "    return clean_frames, clean_indices\n",
        "\n",
        "\n",
        "def visualize_hand_detection(\n",
        "    frame: np.ndarray,\n",
        "    results: Any,\n",
        "    title: str = \"Hand Detection\"\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Visualize MediaPipe hand detection results on a frame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame in BGR format.\n",
        "    results : Any\n",
        "        MediaPipe hand detection results.\n",
        "    title : str\n",
        "        Title for the visualization.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Frame with hand landmarks drawn.\n",
        "    \"\"\"\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "    mp_hands_module = mp.solutions.hands\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated_frame,\n",
        "                hand_landmarks,\n",
        "                mp_hands_module.HAND_CONNECTIONS,\n",
        "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
        "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
        "            )\n",
        "\n",
        "    # Add title\n",
        "    cv2.putText(\n",
        "        annotated_frame, title,\n",
        "        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2\n",
        "    )\n",
        "\n",
        "    return annotated_frame\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# IMAGE PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_sobel_log(\n",
        "    frame: np.ndarray,\n",
        "    sobel_ksize: int = 3,\n",
        "    log_sigma: float = 1.0,\n",
        "    log_ksize: int = 5\n",
        ") -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Apply Sobel + Laplacian of Gaussian (LoG) preprocessing.\n",
        "\n",
        "    This preprocessing helps enhance edges for visualization and potentially\n",
        "    aids in corner detection.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame in BGR format.\n",
        "    sobel_ksize : int\n",
        "        Kernel size for Sobel operator (must be 1, 3, 5, or 7).\n",
        "    log_sigma : float\n",
        "        Standard deviation for Gaussian blur in LoG.\n",
        "    log_ksize : int\n",
        "        Kernel size for Gaussian blur in LoG.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, np.ndarray]\n",
        "        Dictionary containing:\n",
        "        - 'gray': Grayscale image\n",
        "        - 'sobel_x': Sobel gradient in X direction\n",
        "        - 'sobel_y': Sobel gradient in Y direction\n",
        "        - 'sobel_magnitude': Combined Sobel magnitude\n",
        "        - 'gaussian_blur': Gaussian blurred image\n",
        "        - 'log': Laplacian of Gaussian result\n",
        "        - 'combined': Combined edge detection result\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> preprocessed = preprocess_sobel_log(frame)\n",
        "    >>> plt.imshow(preprocessed['combined'], cmap='gray')\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    if len(frame.shape) == 3:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = frame.copy()\n",
        "\n",
        "    # Sobel gradients\n",
        "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_ksize)\n",
        "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_ksize)\n",
        "\n",
        "    # Sobel magnitude\n",
        "    sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "    sobel_magnitude = np.uint8(255 * sobel_magnitude / sobel_magnitude.max())\n",
        "\n",
        "    # Gaussian blur for LoG\n",
        "    gaussian_blur = cv2.GaussianBlur(gray, (log_ksize, log_ksize), log_sigma)\n",
        "\n",
        "    # Laplacian of Gaussian\n",
        "    log_result = cv2.Laplacian(gaussian_blur, cv2.CV_64F)\n",
        "    log_result = np.uint8(np.abs(log_result))\n",
        "\n",
        "    # Normalize LoG\n",
        "    if log_result.max() > 0:\n",
        "        log_normalized = np.uint8(255 * log_result / log_result.max())\n",
        "    else:\n",
        "        log_normalized = log_result\n",
        "\n",
        "    # Combined result: weighted sum of Sobel and LoG\n",
        "    combined = cv2.addWeighted(sobel_magnitude, 0.5, log_normalized, 0.5, 0)\n",
        "\n",
        "    return {\n",
        "        'gray': gray,\n",
        "        'sobel_x': np.uint8(np.abs(sobel_x)),\n",
        "        'sobel_y': np.uint8(np.abs(sobel_y)),\n",
        "        'sobel_magnitude': sobel_magnitude,\n",
        "        'gaussian_blur': gaussian_blur,\n",
        "        'log': log_normalized,\n",
        "        'combined': combined\n",
        "    }\n",
        "\n",
        "\n",
        "def visualize_preprocessing(\n",
        "    preprocessed: Dict[str, np.ndarray],\n",
        "    original_frame: np.ndarray,\n",
        "    figsize: Tuple[int, int] = (16, 10)\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualize all preprocessing stages.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    preprocessed : Dict[str, np.ndarray]\n",
        "        Output from preprocess_sobel_log().\n",
        "    original_frame : np.ndarray\n",
        "        Original BGR frame.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size for matplotlib.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 4, figsize=figsize)\n",
        "\n",
        "    # Original image\n",
        "    axes[0, 0].imshow(cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB))\n",
        "    axes[0, 0].set_title('Original Frame')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Grayscale\n",
        "    axes[0, 1].imshow(preprocessed['gray'], cmap='gray')\n",
        "    axes[0, 1].set_title('Grayscale')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    # Sobel X\n",
        "    axes[0, 2].imshow(preprocessed['sobel_x'], cmap='gray')\n",
        "    axes[0, 2].set_title('Sobel X')\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    # Sobel Y\n",
        "    axes[0, 3].imshow(preprocessed['sobel_y'], cmap='gray')\n",
        "    axes[0, 3].set_title('Sobel Y')\n",
        "    axes[0, 3].axis('off')\n",
        "\n",
        "    # Sobel Magnitude\n",
        "    axes[1, 0].imshow(preprocessed['sobel_magnitude'], cmap='gray')\n",
        "    axes[1, 0].set_title('Sobel Magnitude')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    # Gaussian Blur\n",
        "    axes[1, 1].imshow(preprocessed['gaussian_blur'], cmap='gray')\n",
        "    axes[1, 1].set_title('Gaussian Blur')\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    # LoG\n",
        "    axes[1, 2].imshow(preprocessed['log'], cmap='gray')\n",
        "    axes[1, 2].set_title('Laplacian of Gaussian')\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "    # Combined\n",
        "    axes[1, 3].imshow(preprocessed['combined'], cmap='gray')\n",
        "    axes[1, 3].set_title('Combined (Sobel + LoG)')\n",
        "    axes[1, 3].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Preprocessing Pipeline: Sobel + Laplacian of Gaussian', y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CORNER DETECTION (U-Net)\n",
        "# ============================================================================\n",
        "\n",
        "def detect_corners_unet(\n",
        "    frame: np.ndarray,\n",
        "    unet_model: Any\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Detect 4 board corners using the given U-Net model.\n",
        "\n",
        "    NEW:\n",
        "    - Before running U-Net, we pad the frame with a black border\n",
        "      (width/2 on each side), so the network sees a zoomed-out view.\n",
        "    - After getting corner positions in the padded coordinates, we\n",
        "      remove the padding offset so that the returned corners are\n",
        "      in the original frame coordinate system (width x width).\n",
        "\n",
        "    Steps:\n",
        "      1. Pad frame with black border (pad = width/2 on each side).\n",
        "      2. Apply Sobel + LoG on the padded frame.\n",
        "      3. Run U-Net on both preprocessed images.\n",
        "      4. Extract 4 corners from each mask.\n",
        "      5. Average the two sets of corners.\n",
        "      6. Subtract padding offset -> corners in original frame.\n",
        "    \"\"\"\n",
        "    # -------------------------------------------------------------\n",
        "    # 0) Pad the frame with black border for U-Net ONLY\n",
        "    # -------------------------------------------------------------\n",
        "    padded_frame, (offset_x, offset_y) = pad_frame_for_unet(frame, pad_ratio=0.5)\n",
        "\n",
        "    # 1. Preprocess for Sobel and LoG (on padded frame)\n",
        "    sobel_img = apply_sobel(padded_frame)\n",
        "    log_img   = apply_log(padded_frame)\n",
        "\n",
        "    # 2. Predict masks with U-Net (on padded images)\n",
        "    mask_sobel = unet_predict(unet_model, sobel_img)\n",
        "    mask_log   = unet_predict(unet_model, log_img)\n",
        "\n",
        "    # 3. Extract corners from each mask (in padded coordinates)\n",
        "    corners_sobel = extract_corners(mask_sobel)\n",
        "    corners_log   = extract_corners(mask_log)\n",
        "\n",
        "    if corners_sobel is None or corners_log is None:\n",
        "        raise RuntimeError(\"U-Net corner detection failed: one method returned None\")\n",
        "\n",
        "    if corners_sobel.shape != (4, 2) or corners_log.shape != (4, 2):\n",
        "        raise RuntimeError(\n",
        "            f\"Expected (4,2) corners, got {corners_sobel.shape} and {corners_log.shape}\"\n",
        "        )\n",
        "\n",
        "    # 4. Average the two results (still in padded coordinates)\n",
        "    corners_avg = (corners_sobel.astype(np.float32) + corners_log.astype(np.float32)) / 2.0\n",
        "\n",
        "    # 5. Remove padding offset to go back to ORIGINAL frame coordinates\n",
        "    corners_unpadded = corners_avg.copy()\n",
        "    corners_unpadded[:, 0] -= float(offset_x)\n",
        "    corners_unpadded[:, 1] -= float(offset_y)\n",
        "\n",
        "    return corners_unpadded\n",
        "\n",
        "\n",
        "\n",
        "def extract_corners_from_heatmap(\n",
        "    heatmap: np.ndarray,\n",
        "    threshold: float,\n",
        "    input_size: Tuple[int, int]\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extract corner positions from U-Net heatmap output.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    heatmap : np.ndarray\n",
        "        Heatmap output from U-Net with shape (1, H, W, 4) or (1, 4, H, W).\n",
        "    threshold : float\n",
        "        Minimum threshold for corner detection.\n",
        "    input_size : Tuple[int, int]\n",
        "        Size of the input image.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Array of shape (4, 2) with corner positions.\n",
        "    \"\"\"\n",
        "    # Remove batch dimension\n",
        "    heatmap = np.squeeze(heatmap)\n",
        "\n",
        "    # Handle different channel orderings\n",
        "    if heatmap.shape[0] == 4:  # (4, H, W)\n",
        "        heatmap = np.transpose(heatmap, (1, 2, 0))\n",
        "\n",
        "    corners = []\n",
        "\n",
        "    for i in range(4):\n",
        "        # Get the i-th corner's heatmap\n",
        "        corner_heatmap = heatmap[:, :, i]\n",
        "\n",
        "        # Apply threshold\n",
        "        corner_heatmap_thresh = corner_heatmap.copy()\n",
        "        corner_heatmap_thresh[corner_heatmap_thresh < threshold] = 0\n",
        "\n",
        "        # Find the position of maximum value\n",
        "        if corner_heatmap_thresh.max() > 0:\n",
        "            # Use weighted centroid for sub-pixel accuracy\n",
        "            y_indices, x_indices = np.where(corner_heatmap_thresh > 0)\n",
        "            weights = corner_heatmap_thresh[y_indices, x_indices]\n",
        "\n",
        "            cx = np.average(x_indices, weights=weights)\n",
        "            cy = np.average(y_indices, weights=weights)\n",
        "        else:\n",
        "            # Fallback to argmax\n",
        "            max_idx = np.argmax(corner_heatmap)\n",
        "            cy, cx = np.unravel_index(max_idx, corner_heatmap.shape)\n",
        "\n",
        "        corners.append([cx, cy])\n",
        "\n",
        "    return np.array(corners)\n",
        "\n",
        "\n",
        "def visualize_unet_corners(\n",
        "    frame: np.ndarray,\n",
        "    corners: np.ndarray,\n",
        "    title: str = \"U-Net Corner Detection\"\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualize detected corners on the original frame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Original BGR frame.\n",
        "    corners : np.ndarray\n",
        "        Array of shape (4, 2) with corner positions.\n",
        "    title : str\n",
        "        Title for the plot.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
        "\n",
        "    # Display the frame\n",
        "    ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Define colors for each corner\n",
        "    corner_colors = ['red', 'green', 'blue', 'orange']\n",
        "    corner_labels = ['Corner 1', 'Corner 2', 'Corner 3', 'Corner 4']\n",
        "\n",
        "    # Plot corners\n",
        "    for i, (corner, color, label) in enumerate(zip(corners, corner_colors, corner_labels)):\n",
        "        ax.scatter(corner[0], corner[1], c=color, s=200, marker='o',\n",
        "                   edgecolors='white', linewidths=2, zorder=5)\n",
        "        ax.annotate(f'{label}\\n({corner[0]:.0f}, {corner[1]:.0f})',\n",
        "                   (corner[0], corner[1]),\n",
        "                   textcoords=\"offset points\",\n",
        "                   xytext=(10, 10),\n",
        "                   fontsize=10,\n",
        "                   color=color,\n",
        "                   fontweight='bold',\n",
        "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "\n",
        "    # Draw lines connecting corners (as a quadrilateral)\n",
        "    # First, we need to order them properly\n",
        "    corners_ordered = order_points_clockwise(corners)\n",
        "    for i in range(4):\n",
        "        start = corners_ordered[i]\n",
        "        end = corners_ordered[(i + 1) % 4]\n",
        "        ax.plot([start[0], end[0]], [start[1], end[1]],\n",
        "               'c-', linewidth=2, alpha=0.7)\n",
        "\n",
        "    ax.set_title(title, fontsize=14)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def order_points_clockwise(pts: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Order points in clockwise order starting from top-left.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pts : np.ndarray\n",
        "        Array of shape (4, 2) with unordered points.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Array of shape (4, 2) with points ordered as [TL, TR, BR, BL].\n",
        "    \"\"\"\n",
        "    pts = np.array(pts)\n",
        "\n",
        "    # Sort by sum of coordinates (top-left has smallest sum, bottom-right has largest)\n",
        "    s = pts.sum(axis=1)\n",
        "\n",
        "    # Sort by difference of coordinates (top-right has smallest diff, bottom-left has largest)\n",
        "    d = np.diff(pts, axis=1).flatten()\n",
        "\n",
        "    ordered = np.zeros((4, 2), dtype=np.float32)\n",
        "    ordered[0] = pts[np.argmin(s)]  # Top-left\n",
        "    ordered[2] = pts[np.argmax(s)]  # Bottom-right\n",
        "    ordered[1] = pts[np.argmin(d)]  # Top-right\n",
        "    ordered[3] = pts[np.argmax(d)]  # Bottom-left\n",
        "\n",
        "    return ordered\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ROTATION ESTIMATION (OCR + VLM)\n",
        "# ============================================================================\n",
        "\n",
        "def estimate_rotation_with_vlm(\n",
        "    frame: np.ndarray,\n",
        "    corners: np.ndarray,\n",
        "    ocr_model: Any,\n",
        "    vlm_client: Any,\n",
        "    visualize: bool = True\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Use OCR + VLM reasoning to estimate the board rotation angle.\n",
        "\n",
        "    This function:\n",
        "    1. Crops regions around the board edges where file letters (a-h) and\n",
        "       rank numbers (1-8) should appear.\n",
        "    2. Runs OCR on these regions to detect any visible text.\n",
        "    3. Uses a VLM (Vision Language Model) to reason about the orientation\n",
        "       based on detected text and visual analysis.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame in BGR format.\n",
        "    corners : np.ndarray\n",
        "        Array of shape (4, 2) with the four board corners.\n",
        "    ocr_model : Any\n",
        "        Pre-initialized OCR model (e.g., EasyOCR reader, Tesseract, etc.).\n",
        "    vlm_client : Any\n",
        "        Pre-initialized VLM client (e.g., OpenAI API, Claude, etc.).\n",
        "    visualize : bool\n",
        "        If True, display visualization of cropped regions.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        Estimated rotation in degrees: 0, 90, 180, or 270.\n",
        "        - 0°: White at bottom (standard orientation)\n",
        "        - 90°: White at right\n",
        "        - 180°: White at top\n",
        "        - 270°: White at left\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The function handles cases where OCR may not detect clear text by\n",
        "    combining multiple signals:\n",
        "    - Detected file letters (a-h)\n",
        "    - Detected rank numbers (1-8)\n",
        "    - VLM reasoning about piece positions and board appearance\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> rotation = estimate_rotation_with_vlm(frame, corners, ocr_model, vlm_client)\n",
        "    >>> print(f\"Board rotation: {rotation}°\")\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Step 1: Order corners and compute edge regions\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    corners_ordered = order_points_clockwise(corners)\n",
        "    tl, tr, br, bl = corners_ordered\n",
        "\n",
        "    # Calculate border regions for OCR\n",
        "    # These regions extend outward from each edge of the board\n",
        "    border_width = 60  # pixels\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Step 2: Crop the four edge regions\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    edge_crops = {}\n",
        "    edge_regions = {}\n",
        "\n",
        "    # Top edge (potential rank numbers or file letters)\n",
        "    edge_regions['top'] = crop_edge_region(frame, tl, tr, 'top', border_width)\n",
        "\n",
        "    # Bottom edge\n",
        "    edge_regions['bottom'] = crop_edge_region(frame, bl, br, 'bottom', border_width)\n",
        "\n",
        "    # Left edge\n",
        "    edge_regions['left'] = crop_edge_region(frame, tl, bl, 'left', border_width)\n",
        "\n",
        "    # Right edge\n",
        "    edge_regions['right'] = crop_edge_region(frame, tr, br, 'right', border_width)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Step 3: Run OCR on each edge region\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    ocr_results = {}\n",
        "\n",
        "    for edge_name, region in edge_regions.items():\n",
        "        if region is not None and region.size > 0:\n",
        "            try:\n",
        "                # Run OCR (adapt based on your OCR model's API)\n",
        "                detected_text = run_ocr(region, ocr_model)\n",
        "                ocr_results[edge_name] = detected_text\n",
        "            except Exception as e:\n",
        "                print(f\"OCR failed for {edge_name} edge: {e}\")\n",
        "                ocr_results[edge_name] = []\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Step 4: Analyze OCR results\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    file_letters = set('abcdefgh')\n",
        "    rank_numbers = set('12345678')\n",
        "\n",
        "    edge_analysis = {}\n",
        "    for edge_name, texts in ocr_results.items():\n",
        "        edge_analysis[edge_name] = {\n",
        "            'files': [],\n",
        "            'ranks': [],\n",
        "            'raw': texts\n",
        "        }\n",
        "\n",
        "        for text in texts:\n",
        "            text_lower = text.lower().strip()\n",
        "            for char in text_lower:\n",
        "                if char in file_letters:\n",
        "                    edge_analysis[edge_name]['files'].append(char)\n",
        "                if char in rank_numbers:\n",
        "                    edge_analysis[edge_name]['ranks'].append(char)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Step 5: Use VLM for reasoning (or rule-based fallback)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    rotation = determine_rotation_from_analysis(\n",
        "        edge_analysis, frame, corners_ordered, vlm_client\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Step 6: Visualization\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    if visualize:\n",
        "        visualize_rotation_estimation(\n",
        "            frame, corners_ordered, edge_regions, ocr_results, rotation\n",
        "        )\n",
        "\n",
        "    return rotation\n",
        "\n",
        "\n",
        "def crop_edge_region(\n",
        "    frame: np.ndarray,\n",
        "    corner1: np.ndarray,\n",
        "    corner2: np.ndarray,\n",
        "    edge_type: str,\n",
        "    border_width: int\n",
        ") -> Optional[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Crop the region along a board edge where labels might appear.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame.\n",
        "    corner1, corner2 : np.ndarray\n",
        "        Two corners defining the edge.\n",
        "    edge_type : str\n",
        "        One of 'top', 'bottom', 'left', 'right'.\n",
        "    border_width : int\n",
        "        Width of the border region to crop.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Optional[np.ndarray]\n",
        "        Cropped region, or None if invalid.\n",
        "    \"\"\"\n",
        "    h, w = frame.shape[:2]\n",
        "\n",
        "    # Calculate the direction vector along the edge\n",
        "    edge_vec = corner2 - corner1\n",
        "    edge_length = np.linalg.norm(edge_vec)\n",
        "\n",
        "    if edge_length < 10:  # Too small\n",
        "        return None\n",
        "\n",
        "    # Normalize\n",
        "    edge_unit = edge_vec / edge_length\n",
        "\n",
        "    # Perpendicular vector (outward from board)\n",
        "    if edge_type == 'top':\n",
        "        perp = np.array([edge_unit[1], -edge_unit[0]])  # Upward\n",
        "    elif edge_type == 'bottom':\n",
        "        perp = np.array([-edge_unit[1], edge_unit[0]])  # Downward\n",
        "    elif edge_type == 'left':\n",
        "        perp = np.array([edge_unit[1], -edge_unit[0]])  # Leftward\n",
        "    else:  # right\n",
        "        perp = np.array([-edge_unit[1], edge_unit[0]])  # Rightward\n",
        "\n",
        "    # Define the crop quadrilateral\n",
        "    p1 = corner1\n",
        "    p2 = corner2\n",
        "    p3 = corner2 + perp * border_width\n",
        "    p4 = corner1 + perp * border_width\n",
        "\n",
        "    # Create a bounding box\n",
        "    all_pts = np.array([p1, p2, p3, p4])\n",
        "    x_min = max(0, int(np.min(all_pts[:, 0])))\n",
        "    x_max = min(w, int(np.max(all_pts[:, 0])))\n",
        "    y_min = max(0, int(np.min(all_pts[:, 1])))\n",
        "    y_max = min(h, int(np.max(all_pts[:, 1])))\n",
        "\n",
        "    if x_max <= x_min or y_max <= y_min:\n",
        "        return None\n",
        "\n",
        "    crop = frame[y_min:y_max, x_min:x_max]\n",
        "    return crop\n",
        "\n",
        "\n",
        "def run_ocr(region: np.ndarray, ocr_model: Any) -> List[str]:\n",
        "    \"\"\"\n",
        "    Run OCR on a cropped region.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    region : np.ndarray\n",
        "        Cropped image region.\n",
        "    ocr_model : Any\n",
        "        OCR model instance.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "        List of detected text strings.\n",
        "    \"\"\"\n",
        "    # This implementation assumes EasyOCR-like API\n",
        "    # Adapt based on your specific OCR model\n",
        "\n",
        "    try:\n",
        "        # EasyOCR style\n",
        "        results = ocr_model.readtext(region)\n",
        "        texts = [result[1] for result in results]\n",
        "    except AttributeError:\n",
        "        try:\n",
        "            # Tesseract style (pytesseract)\n",
        "            import pytesseract\n",
        "            text = pytesseract.image_to_string(region)\n",
        "            texts = [t.strip() for t in text.split() if t.strip()]\n",
        "        except:\n",
        "            # Generic fallback\n",
        "            texts = []\n",
        "\n",
        "    return texts\n",
        "\n",
        "\n",
        "def determine_rotation_from_analysis(\n",
        "    edge_analysis: Dict,\n",
        "    frame: np.ndarray,\n",
        "    corners: np.ndarray,\n",
        "    vlm_client: Any\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Determine board rotation from edge analysis and VLM reasoning.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    edge_analysis : Dict\n",
        "        Analysis of OCR results for each edge.\n",
        "    frame : np.ndarray\n",
        "        Original frame.\n",
        "    corners : np.ndarray\n",
        "        Ordered corners [TL, TR, BR, BL].\n",
        "    vlm_client : Any\n",
        "        VLM client for reasoning.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        Rotation in degrees (0, 90, 180, or 270).\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Rule-based analysis first\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Standard orientation: files (a-h) on bottom/top, ranks (1-8) on left/right\n",
        "    # White starts at bottom (ranks 1-2), Black at top (ranks 7-8)\n",
        "\n",
        "    scores = {0: 0, 90: 0, 180: 0, 270: 0}\n",
        "\n",
        "    # Check for file letters (a-h)\n",
        "    if edge_analysis['bottom']['files']:\n",
        "        # Files at bottom suggest 0° or 180°\n",
        "        files = edge_analysis['bottom']['files']\n",
        "        if 'a' in files or 'b' in files:\n",
        "            scores[0] += 2  # White's view\n",
        "        if 'h' in files or 'g' in files:\n",
        "            scores[180] += 2  # Black's view\n",
        "\n",
        "    if edge_analysis['top']['files']:\n",
        "        files = edge_analysis['top']['files']\n",
        "        if 'h' in files or 'g' in files:\n",
        "            scores[0] += 2\n",
        "        if 'a' in files or 'b' in files:\n",
        "            scores[180] += 2\n",
        "\n",
        "    # Check for rank numbers (1-8)\n",
        "    if edge_analysis['left']['ranks']:\n",
        "        ranks = edge_analysis['left']['ranks']\n",
        "        if '1' in ranks or '2' in ranks:\n",
        "            scores[0] += 2\n",
        "        if '8' in ranks or '7' in ranks:\n",
        "            scores[180] += 2\n",
        "\n",
        "    if edge_analysis['right']['ranks']:\n",
        "        ranks = edge_analysis['right']['ranks']\n",
        "        if '8' in ranks or '7' in ranks:\n",
        "            scores[0] += 2\n",
        "        if '1' in ranks or '2' in ranks:\n",
        "            scores[180] += 2\n",
        "\n",
        "    # Check for rotated orientation (90° or 270°)\n",
        "    if edge_analysis['bottom']['ranks'] or edge_analysis['top']['ranks']:\n",
        "        if edge_analysis['bottom']['ranks']:\n",
        "            ranks = edge_analysis['bottom']['ranks']\n",
        "            if '1' in ranks or '2' in ranks:\n",
        "                scores[90] += 2\n",
        "            if '8' in ranks or '7' in ranks:\n",
        "                scores[270] += 2\n",
        "        if edge_analysis['top']['ranks']:\n",
        "            ranks = edge_analysis['top']['ranks']\n",
        "            if '8' in ranks or '7' in ranks:\n",
        "                scores[90] += 2\n",
        "            if '1' in ranks or '2' in ranks:\n",
        "                scores[270] += 2\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # VLM reasoning for ambiguous cases\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    max_score = max(scores.values())\n",
        "\n",
        "    # If scores are tied or low confidence, use VLM\n",
        "    if max_score < 2 or list(scores.values()).count(max_score) > 1:\n",
        "        vlm_rotation = query_vlm_for_rotation(frame, corners, vlm_client)\n",
        "        if vlm_rotation is not None:\n",
        "            return vlm_rotation\n",
        "\n",
        "    # Return the rotation with highest score\n",
        "    return max(scores, key=scores.get)\n",
        "\n",
        "\n",
        "def query_vlm_for_rotation(\n",
        "    frame: np.ndarray,\n",
        "    corners: np.ndarray,\n",
        "    vlm_client: Any\n",
        ") -> Optional[int]:\n",
        "    \"\"\"\n",
        "    Query VLM to determine board rotation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame.\n",
        "    corners : np.ndarray\n",
        "        Ordered corners.\n",
        "    vlm_client : Any\n",
        "        VLM client.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Optional[int]\n",
        "        Rotation in degrees, or None if VLM is unavailable.\n",
        "    \"\"\"\n",
        "    if vlm_client is None:\n",
        "        print(\"[VLM] vlm_client is None, skipping VLM\")\n",
        "        return None\n",
        "\n",
        "    print(\"[VLM] Calling Gemini for rotation...\")\n",
        "\n",
        "    # Prepare the prompt\n",
        "    prompt = \"\"\"\n",
        "    You are given an image of a real chessboard. Your ONLY task is to locate the coordinate labels\n",
        "    (the printed letters a–h and numbers 1–8) around the edges of the board and determine which edge\n",
        "    corresponds to White's home side (rank 1).\n",
        "\n",
        "    CRITICAL RULES (follow strictly):\n",
        "    1. Identify the edge where the FILE LETTERS appear in STRICT INCREASING ORDER:\n",
        "          a b c d e f g h\n",
        "      - These letters must appear left-to-right in that order ON THAT EDGE.\n",
        "      - If the letters appear reversed (h g f ... a), then that is NOT the White side.\n",
        "\n",
        "    2. Completely IGNORE:\n",
        "      - Chess pieces\n",
        "      - Board colors or orientation\n",
        "      - Perspective distortion\n",
        "      - Lighting or reflections\n",
        "      - Any visual cues OTHER than the printed coordinate letters/numbers\n",
        "\n",
        "    3. After identifying the correct White-side edge, output the rotation angle based on its\n",
        "      position IN THE IMAGE (not in real world):\n",
        "\n",
        "      - Output **0**   if the a→b→c→d→e→f→g→h sequence is on the BOTTOM edge of the image.\n",
        "      - Output **90**  if the a→b→c→d→e→f→g→h sequence is on the LEFT edge of the image.\n",
        "      - Output **180** if the a→b→c→d→e→f→g→h sequence is on the TOP edge of the image.\n",
        "      - Output **270** if the a→b→c→d→e→f→g→h sequence is on the RIGHT edge of the image.\n",
        "\n",
        "    SANITY CHECK (mandatory):\n",
        "    - If the letters appear top-to-bottom or bottom-to-top, treat that as LEFT or RIGHT edge.\n",
        "    - If the letters appear reversed (h→a) on the bottom (h→g→f→e→d→c→b→a), then the correct edge is the opposite side.\n",
        "\n",
        "    FINAL INSTRUCTIONS:\n",
        "    - Respond with ONLY ONE INTEGER: 0, 90, 180, or 270.\n",
        "    - No words. No punctuation. No explanation. Only the number.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        # This is a generic VLM API call - adapt for your specific VLM\n",
        "        # Example for OpenAI-style API:\n",
        "\n",
        "        # Encode image to base64\n",
        "        import base64\n",
        "        _, buffer = cv2.imencode('.jpg', frame)\n",
        "        image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "        # # Make API call (pseudo-code - adapt to your VLM client)\n",
        "        # response = vlm_client.analyze(\n",
        "        #     image=image_base64,\n",
        "        #     prompt=prompt\n",
        "        # )\n",
        "\n",
        "\n",
        "        # # Parse response\n",
        "        # response_text = str(response).strip()\n",
        "\n",
        "        # print(\"[VLM] Parsed response:\", response_text)\n",
        "        # for rotation in [0, 90, 180, 270]:\n",
        "        #     if str(rotation) in response_text:\n",
        "        #         return rotation\n",
        "\n",
        "        response_text = vlm_client.analyze(image_base64, prompt)\n",
        "        response_text = (response_text or \"\").strip()\n",
        "        print(\"[VLM] Raw Gemini response:\", repr(response_text))\n",
        "\n",
        "        # Regex: match whole number 0 or 90 or 180 or 270\n",
        "        m = re.search(r'\\b(0|90|180|270)\\b', response_text)\n",
        "        if m:\n",
        "            rotation = int(m.group(1))\n",
        "            print(\"[VLM] Parsed rotation:\", rotation)\n",
        "            return rotation\n",
        "        else:\n",
        "            print(\"[VLM] Could not parse rotation from response\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"VLM query failed: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def visualize_rotation_estimation(\n",
        "    frame: np.ndarray,\n",
        "    corners: np.ndarray,\n",
        "    edge_regions: Dict[str, np.ndarray],\n",
        "    ocr_results: Dict[str, List[str]],\n",
        "    rotation: int\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualize the rotation estimation process.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Original frame.\n",
        "    corners : np.ndarray\n",
        "        Ordered corners.\n",
        "    edge_regions : Dict[str, np.ndarray]\n",
        "        Cropped edge regions.\n",
        "    ocr_results : Dict[str, List[str]]\n",
        "        OCR results for each edge.\n",
        "    rotation : int\n",
        "        Estimated rotation.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Main image with corners\n",
        "    ax1 = fig.add_subplot(2, 3, 1)\n",
        "    ax1.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Draw corners and edges\n",
        "    colors = ['red', 'green', 'blue', 'orange']\n",
        "    labels = ['TL', 'TR', 'BR', 'BL']\n",
        "    for i, (corner, color, label) in enumerate(zip(corners, colors, labels)):\n",
        "        ax1.scatter(corner[0], corner[1], c=color, s=100, zorder=5)\n",
        "        ax1.annotate(label, corner, fontsize=10, color=color)\n",
        "\n",
        "    # Draw quadrilateral\n",
        "    corners_closed = np.vstack([corners, corners[0]])\n",
        "    ax1.plot(corners_closed[:, 0], corners_closed[:, 1], 'c-', linewidth=2)\n",
        "    ax1.set_title(f'Detected Board\\nEstimated Rotation: {rotation}°')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Edge regions\n",
        "    edge_names = ['top', 'bottom', 'left', 'right']\n",
        "    positions = [(2, 3, 2), (2, 3, 5), (2, 3, 4), (2, 3, 3)]\n",
        "\n",
        "    for edge_name, pos in zip(edge_names, positions):\n",
        "        ax = fig.add_subplot(*pos)\n",
        "        region = edge_regions.get(edge_name)\n",
        "\n",
        "        if region is not None and region.size > 0:\n",
        "            ax.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n",
        "            ocr_text = ocr_results.get(edge_name, [])\n",
        "            ax.set_title(f'{edge_name.capitalize()} Edge\\nOCR: {ocr_text}')\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, 'No Region', ha='center', va='center')\n",
        "            ax.set_title(f'{edge_name.capitalize()} Edge')\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Rotation indicator\n",
        "    ax6 = fig.add_subplot(2, 3, 6)\n",
        "\n",
        "    # Draw rotation diagram\n",
        "    theta = np.radians(rotation)\n",
        "    ax6.arrow(0, 0, np.cos(theta) * 0.8, np.sin(theta) * 0.8,\n",
        "             head_width=0.1, head_length=0.1, fc='blue', ec='blue')\n",
        "    ax6.set_xlim(-1, 1)\n",
        "    ax6.set_ylim(-1, 1)\n",
        "    ax6.set_aspect('equal')\n",
        "    ax6.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "    ax6.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
        "    ax6.set_title(f'Rotation: {rotation}°\\n(0° = White at bottom)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CORNER ORDERING AND HOMOGRAPHY\n",
        "# ============================================================================\n",
        "\n",
        "def order_corners_tl_tr_br_bl(\n",
        "    corners: np.ndarray,\n",
        "    rotation_deg: int\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Order corners as [TL, TR, BR, BL] based on the known board rotation.\n",
        "\n",
        "    This function takes corners in arbitrary order and reorders them based\n",
        "    on the board's rotation relative to the camera view.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corners : np.ndarray\n",
        "        Array of shape (4, 2) with corner coordinates in arbitrary order.\n",
        "    rotation_deg : int\n",
        "        Board rotation in degrees (0, 90, 180, or 270).\n",
        "        - 0°: a1 is at bottom-left of image\n",
        "        - 90°: a1 is at bottom-right of image\n",
        "        - 180°: a1 is at top-right of image\n",
        "        - 270°: a1 is at top-left of image\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Array of shape (4, 2) with corners ordered as [TL, TR, BR, BL]\n",
        "        in image coordinates, where:\n",
        "        - TL: Top-left of the board (h8 after rotation correction)\n",
        "        - TR: Top-right of the board\n",
        "        - BR: Bottom-right of the board\n",
        "        - BL: Bottom-left of the board (a1 after rotation correction)\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> corners = np.array([[100, 100], [500, 100], [500, 500], [100, 500]])\n",
        "    >>> ordered = order_corners_tl_tr_br_bl(corners, rotation_deg=0)\n",
        "    \"\"\"\n",
        "    # First, get geometrically ordered corners (by position in image)\n",
        "    ordered = order_points_clockwise(corners)\n",
        "\n",
        "    # ordered is now [TL, TR, BR, BL] in IMAGE coordinates\n",
        "    # We need to adjust based on rotation so that our grid mapping is correct\n",
        "\n",
        "    # The rotation tells us where a1 is relative to the image:\n",
        "    # - 0°: a1 at BL -> standard, no adjustment needed\n",
        "    # - 90°: a1 at TL -> rotate corner labels 90° clockwise\n",
        "    # - 180°: a1 at TR -> rotate corner labels 180°\n",
        "    # - 270°: a1 at BR -> rotate corner labels 270° clockwise\n",
        "\n",
        "    # However, for homography, we want corners in consistent image order [TL, TR, BR, BL]\n",
        "    # The rotation will be handled when we assign algebraic names to squares\n",
        "\n",
        "    return ordered\n",
        "\n",
        "\n",
        "def compute_homography(\n",
        "    corners_tl_tr_br_bl: np.ndarray,\n",
        "    board_size: int = DEFAULT_BOARD_SIZE\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Compute homography matrix to warp the board to a square image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corners_tl_tr_br_bl : np.ndarray\n",
        "        Array of shape (4, 2) with corners ordered as [TL, TR, BR, BL].\n",
        "    board_size : int\n",
        "        Size of the output square image (board_size x board_size).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[np.ndarray, np.ndarray]\n",
        "        - H: 3x3 homography matrix\n",
        "        - dst_points: Destination points in the warped image\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The homography maps:\n",
        "    - TL (source) -> (0, 0) (destination)\n",
        "    - TR (source) -> (board_size, 0) (destination)\n",
        "    - BR (source) -> (board_size, board_size) (destination)\n",
        "    - BL (source) -> (0, board_size) (destination)\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> H, dst = compute_homography(corners, board_size=800)\n",
        "    >>> warped = cv2.warpPerspective(frame, H, (800, 800))\n",
        "    \"\"\"\n",
        "    src_points = corners_tl_tr_br_bl.astype(np.float32)\n",
        "\n",
        "    # Destination points for a square board\n",
        "    dst_points = np.array([\n",
        "        [0, 0],                      # Top-left\n",
        "        [board_size - 1, 0],         # Top-right\n",
        "        [board_size - 1, board_size - 1],  # Bottom-right\n",
        "        [0, board_size - 1]          # Bottom-left\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    # Compute homography\n",
        "    H, status = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5.0)\n",
        "\n",
        "    if H is None:\n",
        "        raise ValueError(\"Failed to compute homography matrix\")\n",
        "\n",
        "    return H, dst_points\n",
        "\n",
        "\n",
        "def warp_board(\n",
        "    frame: np.ndarray,\n",
        "    H: np.ndarray,\n",
        "    board_size: int = DEFAULT_BOARD_SIZE\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Apply perspective warp to obtain a top-down view of the board.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame in BGR format.\n",
        "    H : np.ndarray\n",
        "        3x3 homography matrix.\n",
        "    board_size : int\n",
        "        Size of the output square image.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Warped board image of shape (board_size, board_size, 3).\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> H, _ = compute_homography(corners)\n",
        "    >>> warped = warp_board(frame, H, board_size=800)\n",
        "    \"\"\"\n",
        "    warped = cv2.warpPerspective(\n",
        "        frame, H, (board_size, board_size),\n",
        "        flags=cv2.INTER_LINEAR,\n",
        "        borderMode=cv2.BORDER_CONSTANT,\n",
        "        borderValue=(0, 0, 0)\n",
        "    )\n",
        "\n",
        "    return warped\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BOARD GRID COMPUTATION\n",
        "# ============================================================================\n",
        "\n",
        "def compute_board_grid(\n",
        "    board_size: int = DEFAULT_BOARD_SIZE,\n",
        "    n: int = 8,\n",
        "    rotation_deg: int = 0\n",
        ") -> Tuple[np.ndarray, List[str]]:\n",
        "    \"\"\"\n",
        "    Precompute the centers of each of the 8x8 squares in the warped board.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board_size : int\n",
        "        Size of the warped board image.\n",
        "    n : int\n",
        "        Number of squares per side (8 for standard chess).\n",
        "    rotation_deg : int\n",
        "        Board rotation in degrees (0, 90, 180, or 270).\n",
        "        This affects how algebraic names are assigned to squares.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[np.ndarray, List[str]]\n",
        "        - centers: Array of shape (64, 2) with (x, y) coordinates of square centers.\n",
        "        - square_names: List of 64 algebraic names (e.g., ['a1', 'b1', ..., 'h8']).\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The warped image has (0, 0) at top-left and (board_size, board_size) at bottom-right.\n",
        "\n",
        "    With rotation = 0° (White at bottom):\n",
        "    - Top-left square (row=0, col=0) is a8\n",
        "    - Bottom-left square (row=7, col=0) is a1\n",
        "    - Bottom-right square (row=7, col=7) is h1\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> centers, names = compute_board_grid(board_size=800, rotation_deg=0)\n",
        "    >>> print(f\"Square a1 center: {centers[names.index('a1')]}\")\n",
        "    \"\"\"\n",
        "    square_size = board_size / n\n",
        "\n",
        "    centers = []\n",
        "    square_names = []\n",
        "\n",
        "    for row in range(n):  # 0 = top row in image\n",
        "        for col in range(n):  # 0 = left column in image\n",
        "            # Center of this square in pixel coordinates\n",
        "            cx = (col + 0.5) * square_size\n",
        "            cy = (row + 0.5) * square_size\n",
        "            centers.append([cx, cy])\n",
        "\n",
        "            # Determine algebraic name based on rotation\n",
        "            if rotation_deg == 0:\n",
        "                # Standard: a8 at top-left, a1 at bottom-left\n",
        "                file_idx = col\n",
        "                rank_idx = 7 - row\n",
        "            elif rotation_deg == 90:\n",
        "                # Board rotated 90° CW: a1 at top-left\n",
        "                file_idx = row\n",
        "                rank_idx = col\n",
        "            elif rotation_deg == 180:\n",
        "                # Board rotated 180°: h1 at top-left\n",
        "                file_idx = 7 - col\n",
        "                rank_idx = row\n",
        "            elif rotation_deg == 270:\n",
        "                # Board rotated 270° CW (90° CCW): h8 at top-left\n",
        "                file_idx = 7 - row\n",
        "                rank_idx = 7 - col\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid rotation: {rotation_deg}\")\n",
        "\n",
        "            file_char = FILES[file_idx]\n",
        "            rank_char = RANKS[rank_idx]\n",
        "            square_names.append(f\"{file_char}{rank_char}\")\n",
        "\n",
        "    return np.array(centers), square_names\n",
        "\n",
        "\n",
        "def visualize_board_grid(\n",
        "    warped_board: np.ndarray,\n",
        "    centers: np.ndarray,\n",
        "    square_names: List[str],\n",
        "    board_size: int = DEFAULT_BOARD_SIZE,\n",
        "    figsize: Tuple[int, int] = (12, 12)\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualize the board grid with square centers and algebraic names.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    warped_board : np.ndarray\n",
        "        Warped board image.\n",
        "    centers : np.ndarray\n",
        "        Array of shape (64, 2) with square centers.\n",
        "    square_names : List[str]\n",
        "        List of 64 algebraic names.\n",
        "    board_size : int\n",
        "        Size of the warped board.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "\n",
        "    # Display warped board\n",
        "    ax.imshow(cv2.cvtColor(warped_board, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Draw grid lines\n",
        "    square_size = board_size / 8\n",
        "    for i in range(9):\n",
        "        # Vertical lines\n",
        "        ax.axvline(x=i * square_size, color='cyan', linewidth=1, alpha=0.7)\n",
        "        # Horizontal lines\n",
        "        ax.axhline(y=i * square_size, color='cyan', linewidth=1, alpha=0.7)\n",
        "\n",
        "    # Plot centers and names\n",
        "    for center, name in zip(centers, square_names):\n",
        "        ax.scatter(center[0], center[1], c='red', s=30, zorder=5)\n",
        "        ax.annotate(\n",
        "            name,\n",
        "            (center[0], center[1]),\n",
        "            fontsize=8,\n",
        "            color='yellow',\n",
        "            ha='center',\n",
        "            va='center',\n",
        "            fontweight='bold',\n",
        "            bbox=dict(boxstyle='round,pad=0.1', facecolor='black', alpha=0.5)\n",
        "        )\n",
        "\n",
        "    ax.set_title('Warped Board with Grid Centers and Algebraic Names', fontsize=14)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PIECE DETECTION (YOLO)\n",
        "# ============================================================================\n",
        "\n",
        "def detect_pieces_yolo(\n",
        "    frame: np.ndarray,\n",
        "    yolo_model: Any,\n",
        "    conf_thres: float = 0.3,\n",
        "    iou_thres: float = 0.45,\n",
        "    rotation_deg: int = 0\n",
        ") -> List[PieceDetection]:\n",
        "    \"\"\"\n",
        "    Run the pre-trained YOLO model on the original frame to detect chess pieces.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Input frame in BGR format.\n",
        "    yolo_model : Any\n",
        "        Pre-trained YOLO model (already loaded and ready for inference).\n",
        "        Expected to be a YOLOv5/YOLOv8 model or similar.\n",
        "    conf_thres : float\n",
        "        Confidence threshold for detections.\n",
        "    iou_thres : float\n",
        "        IoU threshold for NMS.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[PieceDetection]\n",
        "        List of detected pieces with bounding boxes, centers, class info, etc.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The function assumes the YOLO model is already loaded. Common class names\n",
        "    for chess pieces might include:\n",
        "    - 'white_king', 'white_queen', 'white_rook', etc.\n",
        "    - Or indexed classes that map to piece types.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> detections = detect_pieces_yolo(frame, yolo_model, conf_thres=0.5)\n",
        "    >>> for det in detections:\n",
        "    ...     print(f\"{det.class_name} at {det.center} (conf: {det.confidence:.2f})\")\n",
        "    \"\"\"\n",
        "    detections = []\n",
        "    frame_for_yolo = sharpen_laplacian(frame)\n",
        "    try:\n",
        "        # -------------------------------------------------------------------------\n",
        "        # Option A: YOLOv5/YOLOv8 style (ultralytics)\n",
        "        # -------------------------------------------------------------------------\n",
        "        # Run inference\n",
        "        results = yolo_model(frame, conf=conf_thres, iou=iou_thres, verbose=False)\n",
        "\n",
        "        # Process results\n",
        "        # YOLOv8 returns a list of Results objects\n",
        "        if hasattr(results, '__iter__'):\n",
        "            result = results[0]  # Get first (and usually only) result\n",
        "        else:\n",
        "            result = results\n",
        "\n",
        "        # Get boxes, classes, and confidences\n",
        "        if hasattr(result, 'boxes'):\n",
        "            boxes = result.boxes\n",
        "\n",
        "            for i in range(len(boxes)):\n",
        "                # Get bounding box\n",
        "                box = boxes.xyxy[i].cpu().numpy()\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                # Get class and confidence\n",
        "                conf = float(boxes.conf[i].cpu().numpy())\n",
        "                cls_id = int(boxes.cls[i].cpu().numpy())\n",
        "\n",
        "                # Get class name\n",
        "                if hasattr(result, 'names'):\n",
        "                    cls_name = result.names[cls_id]\n",
        "                else:\n",
        "                    cls_name = str(cls_id)\n",
        "\n",
        "                # Calculate center\n",
        "                cx, cy = compute_piece_center_with_rotation(x1, y1, x2, y2, rotation_deg)\n",
        "\n",
        "\n",
        "                detection = PieceDetection(\n",
        "                    bbox=(x1, y1, x2, y2),\n",
        "                    center=(cx, cy),\n",
        "                    class_id=cls_id,\n",
        "                    class_name=cls_name,\n",
        "                    confidence=conf\n",
        "                )\n",
        "                detections.append(detection)\n",
        "\n",
        "        else:\n",
        "            # -------------------------------------------------------------------------\n",
        "            # Option B: Legacy YOLOv5 style\n",
        "            # -------------------------------------------------------------------------\n",
        "            # results.xyxy[0] contains [x1, y1, x2, y2, confidence, class]\n",
        "            pred = results.xyxy[0].cpu().numpy()\n",
        "\n",
        "            for det in pred:\n",
        "                x1, y1, x2, y2, conf, cls_id = det\n",
        "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "                cls_id = int(cls_id)\n",
        "\n",
        "                # Get class name from model\n",
        "                if hasattr(results, 'names'):\n",
        "                    cls_name = results.names[cls_id]\n",
        "                else:\n",
        "                    cls_name = str(cls_id)\n",
        "\n",
        "                cx, cy = compute_piece_center_with_rotation(x1, y1, x2, y2, rotation_deg)\n",
        "\n",
        "                detection = PieceDetection(\n",
        "                    bbox=(x1, y1, x2, y2),\n",
        "                    center=(cx, cy),\n",
        "                    class_id=cls_id,\n",
        "                    class_name=cls_name,\n",
        "                    confidence=conf\n",
        "                )\n",
        "                detections.append(detection)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"YOLO detection error: {e}\")\n",
        "        print(\"Returning empty detection list.\")\n",
        "\n",
        "    return detections\n",
        "\n",
        "\n",
        "def visualize_yolo_detections(\n",
        "    frame: np.ndarray,\n",
        "    detections: List[PieceDetection],\n",
        "    title: str = \"YOLO Chess Piece Detections\",\n",
        "    figsize: Tuple[int, int] = (14, 10)\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Visualize YOLO detections on the original frame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Original BGR frame.\n",
        "    detections : List[PieceDetection]\n",
        "        List of detected pieces.\n",
        "    title : str\n",
        "        Title for the visualization.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Annotated frame with detection boxes and labels.\n",
        "    \"\"\"\n",
        "    annotated = frame.copy()\n",
        "\n",
        "    # Define colors for different piece types\n",
        "    piece_colors = {\n",
        "        'white': (255, 255, 200),  # Light yellow\n",
        "        'black': (100, 100, 100),  # Dark gray\n",
        "        'default': (0, 255, 0)     # Green\n",
        "    }\n",
        "\n",
        "    for det in detections:\n",
        "        x1, y1, x2, y2 = det.bbox\n",
        "\n",
        "        # Determine color based on piece color\n",
        "        cls_lower = det.class_name.lower()\n",
        "        if 'white' in cls_lower:\n",
        "            color = piece_colors['white']\n",
        "        elif 'black' in cls_lower:\n",
        "            color = piece_colors['black']\n",
        "        else:\n",
        "            color = piece_colors['default']\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        # Draw center point\n",
        "        cx, cy = int(det.center[0]), int(det.center[1])\n",
        "        cv2.circle(annotated, (cx, cy), 5, (0, 0, 255), -1)\n",
        "\n",
        "        # Create label\n",
        "        label = f\"{det.class_name}: {det.confidence:.2f}\"\n",
        "\n",
        "        # Get label size for background\n",
        "        (label_w, label_h), baseline = cv2.getTextSize(\n",
        "            label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1\n",
        "        )\n",
        "\n",
        "        # Draw label background\n",
        "        cv2.rectangle(\n",
        "            annotated,\n",
        "            (x1, y1 - label_h - 10),\n",
        "            (x1 + label_w + 5, y1),\n",
        "            color, -1\n",
        "        )\n",
        "\n",
        "        # Draw label text\n",
        "        text_color = (0, 0, 0) if 'white' in cls_lower else (255, 255, 255)\n",
        "        cv2.putText(\n",
        "            annotated, label,\n",
        "            (x1 + 2, y1 - 5),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1\n",
        "        )\n",
        "\n",
        "    # Display using matplotlib\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "    ax.set_title(f\"{title}\\nDetected {len(detections)} pieces\", fontsize=14)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return annotated\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# POINT PROJECTION AND SQUARE ASSIGNMENT\n",
        "# ============================================================================\n",
        "\n",
        "def project_points_with_homography(\n",
        "    points: np.ndarray,\n",
        "    H: np.ndarray\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Apply homography H to transform points from original to warped coordinates.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    points : np.ndarray\n",
        "        Array of points with shape (N, 2) where each row is (x, y).\n",
        "    H : np.ndarray\n",
        "        3x3 homography matrix.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Transformed points with shape (N, 2).\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    Uses OpenCV's perspectiveTransform for accurate projection.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> original_points = np.array([[100, 200], [300, 400]])\n",
        "    >>> projected = project_points_with_homography(original_points, H)\n",
        "    \"\"\"\n",
        "    if len(points) == 0:\n",
        "        return np.array([])\n",
        "\n",
        "    points = np.array(points, dtype=np.float32)\n",
        "\n",
        "    # OpenCV's perspectiveTransform expects shape (N, 1, 2)\n",
        "    points_reshaped = points.reshape(-1, 1, 2)\n",
        "\n",
        "    # Apply homography\n",
        "    transformed = cv2.perspectiveTransform(points_reshaped, H)\n",
        "\n",
        "    # Reshape back to (N, 2)\n",
        "    return transformed.reshape(-1, 2)\n",
        "\n",
        "\n",
        "def assign_pieces_to_squares(\n",
        "    projected_centers: np.ndarray,\n",
        "    piece_types: List[str],\n",
        "    grid_centers: np.ndarray,\n",
        "    square_names: List[str],\n",
        "    max_distance: float = None\n",
        ") -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Assign each detected piece to its nearest grid square.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    projected_centers : np.ndarray\n",
        "        Array of shape (N, 2) with projected piece centers in warped coordinates.\n",
        "    piece_types : List[str]\n",
        "        List of piece type codes (e.g., ['P', 'N', 'B', ...]) for each detection.\n",
        "    grid_centers : np.ndarray\n",
        "        Array of shape (64, 2) with precomputed square centers.\n",
        "    square_names : List[str]\n",
        "        List of 64 algebraic names for the squares.\n",
        "    max_distance : float, optional\n",
        "        Maximum allowed distance for assignment. If None, uses half the square size.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, str]\n",
        "        Dictionary mapping square name to piece code (e.g., {'e4': 'P', 'a1': 'R'}).\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    If two pieces are assigned to the same square, the one with smaller distance\n",
        "    is kept (could indicate detection error or piece overlap).\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> board = assign_pieces_to_squares(proj_centers, types, grid_centers, names)\n",
        "    >>> print(board)  # {'e4': 'P', 'd4': 'p', ...}\n",
        "    \"\"\"\n",
        "    if len(projected_centers) == 0:\n",
        "        return {}\n",
        "\n",
        "    # Calculate square size for distance threshold\n",
        "    if len(grid_centers) >= 2:\n",
        "        # Estimate square size from grid centers\n",
        "        dx = grid_centers[1][0] - grid_centers[0][0]\n",
        "        square_size = abs(dx) if dx != 0 else 100\n",
        "    else:\n",
        "        square_size = 100\n",
        "\n",
        "    if max_distance is None:\n",
        "        max_distance = square_size * 0.6  # Allow some margin\n",
        "\n",
        "    board = {}\n",
        "    assignment_distances = {}\n",
        "\n",
        "    for i, (center, piece_type) in enumerate(zip(projected_centers, piece_types)):\n",
        "        # Calculate distances to all grid centers\n",
        "        distances = np.sqrt(np.sum((grid_centers - center) ** 2, axis=1))\n",
        "\n",
        "        # Find nearest square\n",
        "        nearest_idx = np.argmin(distances)\n",
        "        min_distance = distances[nearest_idx]\n",
        "\n",
        "        # Check if within threshold\n",
        "        if min_distance <= max_distance:\n",
        "            square_name = square_names[nearest_idx]\n",
        "\n",
        "            # Handle conflicts (multiple pieces assigned to same square)\n",
        "            if square_name in board:\n",
        "                if min_distance < assignment_distances[square_name]:\n",
        "                    # This piece is closer, replace\n",
        "                    board[square_name] = piece_type\n",
        "                    assignment_distances[square_name] = min_distance\n",
        "            else:\n",
        "                board[square_name] = piece_type\n",
        "                assignment_distances[square_name] = min_distance\n",
        "\n",
        "    return board\n",
        "\n",
        "\n",
        "def visualize_piece_assignments(\n",
        "    warped_board: np.ndarray,\n",
        "    projected_centers: np.ndarray,\n",
        "    piece_types: List[str],\n",
        "    grid_centers: np.ndarray,\n",
        "    square_names: List[str],\n",
        "    board_dict: Dict[str, str],\n",
        "    figsize: Tuple[int, int] = (12, 12)\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualize the piece assignments on the warped board.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    warped_board : np.ndarray\n",
        "        Warped board image.\n",
        "    projected_centers : np.ndarray\n",
        "        Projected piece centers.\n",
        "    piece_types : List[str]\n",
        "        Piece type codes.\n",
        "    grid_centers : np.ndarray\n",
        "        Grid square centers.\n",
        "    square_names : List[str]\n",
        "        Square names.\n",
        "    board_dict : Dict[str, str]\n",
        "        Assignment result.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "\n",
        "    # Display warped board\n",
        "    ax.imshow(cv2.cvtColor(warped_board, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Draw grid centers (small dots)\n",
        "    ax.scatter(\n",
        "        grid_centers[:, 0], grid_centers[:, 1],\n",
        "        c='cyan', s=20, alpha=0.5, label='Grid Centers'\n",
        "    )\n",
        "\n",
        "    # Draw projected piece centers\n",
        "    for center, piece_type in zip(projected_centers, piece_types):\n",
        "        is_white = piece_type.isupper()\n",
        "        color = 'yellow' if is_white else 'magenta'\n",
        "\n",
        "        ax.scatter(center[0], center[1], c=color, s=100, marker='x', linewidth=2)\n",
        "        ax.annotate(\n",
        "            piece_type,\n",
        "            (center[0], center[1]),\n",
        "            textcoords=\"offset points\",\n",
        "            xytext=(5, 5),\n",
        "            fontsize=10,\n",
        "            color=color,\n",
        "            fontweight='bold'\n",
        "        )\n",
        "\n",
        "    # Draw assignments\n",
        "    for square_name, piece_type in board_dict.items():\n",
        "        idx = square_names.index(square_name)\n",
        "        grid_center = grid_centers[idx]\n",
        "\n",
        "        ax.scatter(\n",
        "            grid_center[0], grid_center[1],\n",
        "            c='green', s=150, marker='s', alpha=0.3\n",
        "        )\n",
        "        ax.annotate(\n",
        "            f\"{square_name}\\n{piece_type}\",\n",
        "            (grid_center[0], grid_center[1]),\n",
        "            fontsize=8,\n",
        "            color='white',\n",
        "            ha='center',\n",
        "            va='center',\n",
        "            fontweight='bold',\n",
        "            bbox=dict(boxstyle='round,pad=0.2', facecolor='green', alpha=0.7)\n",
        "        )\n",
        "\n",
        "    # Legend\n",
        "    legend_elements = [\n",
        "        Line2D([0], [0], marker='o', color='w', markerfacecolor='cyan',\n",
        "               markersize=8, label='Grid Centers'),\n",
        "        Line2D([0], [0], marker='x', color='yellow', markersize=10,\n",
        "               linestyle='None', label='White Pieces'),\n",
        "        Line2D([0], [0], marker='x', color='magenta', markersize=10,\n",
        "               linestyle='None', label='Black Pieces'),\n",
        "        Line2D([0], [0], marker='s', color='green', markersize=10,\n",
        "               alpha=0.3, linestyle='None', label='Assigned Squares')\n",
        "    ]\n",
        "    ax.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "    ax.set_title(f'Piece Assignments\\n{len(board_dict)} pieces on board', fontsize=14)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BOARD STATE AND FEN CONVERSION\n",
        "# ============================================================================\n",
        "\n",
        "def board_to_fen(board_dict: Dict[str, str]) -> str:\n",
        "    \"\"\"\n",
        "    Convert a board representation to FEN-like string.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board_dict : Dict[str, str]\n",
        "        Dictionary mapping square name to piece code.\n",
        "        - Uppercase for white pieces: K, Q, R, B, N, P\n",
        "        - Lowercase for black pieces: k, q, r, b, n, p\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        FEN position string (piece placement only, not full FEN).\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    FEN notation represents the board from rank 8 to rank 1 (top to bottom),\n",
        "    and from file a to file h (left to right) within each rank.\n",
        "    Empty squares are counted and represented as numbers.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> board = {'e1': 'K', 'e8': 'k', 'd1': 'Q', 'd8': 'q'}\n",
        "    >>> fen = board_to_fen(board)\n",
        "    >>> print(fen)  # '3qk3/8/8/8/8/8/8/3QK3'\n",
        "    \"\"\"\n",
        "    fen_rows = []\n",
        "\n",
        "    for rank in range(8, 0, -1):  # 8 down to 1\n",
        "        row = ''\n",
        "        empty_count = 0\n",
        "\n",
        "        for file in 'abcdefgh':\n",
        "            square = f'{file}{rank}'\n",
        "\n",
        "            if square in board_dict:\n",
        "                if empty_count > 0:\n",
        "                    row += str(empty_count)\n",
        "                    empty_count = 0\n",
        "                row += board_dict[square]\n",
        "            else:\n",
        "                empty_count += 1\n",
        "\n",
        "        if empty_count > 0:\n",
        "            row += str(empty_count)\n",
        "\n",
        "        fen_rows.append(row)\n",
        "\n",
        "    return '/'.join(fen_rows)\n",
        "\n",
        "\n",
        "def fen_to_board(fen: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Convert a FEN position string to board dictionary.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fen : str\n",
        "        FEN position string (piece placement part only).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, str]\n",
        "        Dictionary mapping square name to piece code.\n",
        "    \"\"\"\n",
        "    board = {}\n",
        "    rows = fen.split('/')\n",
        "\n",
        "    for rank_idx, row in enumerate(rows):\n",
        "        rank = 8 - rank_idx  # FEN starts from rank 8\n",
        "        file_idx = 0\n",
        "\n",
        "        for char in row:\n",
        "            if char.isdigit():\n",
        "                file_idx += int(char)\n",
        "            else:\n",
        "                file = FILES[file_idx]\n",
        "                square = f'{file}{rank}'\n",
        "                board[square] = char\n",
        "                file_idx += 1\n",
        "\n",
        "    return board\n",
        "\n",
        "\n",
        "def get_initial_board() -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Get the initial chess board position.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, str]\n",
        "        Starting position with all 32 pieces.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        # White pieces\n",
        "        'a1': 'R', 'b1': 'N', 'c1': 'B', 'd1': 'Q',\n",
        "        'e1': 'K', 'f1': 'B', 'g1': 'N', 'h1': 'R',\n",
        "        'a2': 'P', 'b2': 'P', 'c2': 'P', 'd2': 'P',\n",
        "        'e2': 'P', 'f2': 'P', 'g2': 'P', 'h2': 'P',\n",
        "        # Black pieces\n",
        "        'a7': 'p', 'b7': 'p', 'c7': 'p', 'd7': 'p',\n",
        "        'e7': 'p', 'f7': 'p', 'g7': 'p', 'h7': 'p',\n",
        "        'a8': 'r', 'b8': 'n', 'c8': 'b', 'd8': 'q',\n",
        "        'e8': 'k', 'f8': 'b', 'g8': 'n', 'h8': 'r',\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MOVE DETECTION\n",
        "# ============================================================================\n",
        "\n",
        "def detect_move_from_states(\n",
        "    prev_board: Dict[str, str],\n",
        "    curr_board: Dict[str, str]\n",
        ") -> Optional[Move]:\n",
        "    \"\"\"\n",
        "    Compare two board states and infer the move that was made.\n",
        "\n",
        "    Now includes a robust fallback heuristic that tries to find the\n",
        "    single best candidate move even if there is extra noise from\n",
        "    missed / flickering detections.\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Compute differences\n",
        "    # -------------------------------------------------------------------------\n",
        "    vacated = []   # squares that had a piece but now don't\n",
        "    occupied = []  # squares that now have a piece but didn't before\n",
        "    changed = []   # squares where piece changed to a different one\n",
        "\n",
        "    all_squares = set(prev_board.keys()) | set(curr_board.keys())\n",
        "\n",
        "    for square in all_squares:\n",
        "        prev_piece = prev_board.get(square)\n",
        "        curr_piece = curr_board.get(square)\n",
        "\n",
        "        if prev_piece and not curr_piece:\n",
        "            vacated.append((square, prev_piece))\n",
        "        elif not prev_piece and curr_piece:\n",
        "            occupied.append((square, curr_piece))\n",
        "        elif prev_piece != curr_piece and prev_piece and curr_piece:\n",
        "            changed.append((square, prev_piece, curr_piece))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Case 1: Castling (exact patterns)\n",
        "    # -------------------------------------------------------------------------\n",
        "    if len(vacated) == 2 and len(occupied) == 2:\n",
        "        vacated_squares = {sq for sq, _ in vacated}\n",
        "        occupied_squares = {sq for sq, _ in occupied}\n",
        "\n",
        "        # Kingside / queenside castling for white\n",
        "        if vacated_squares == {'e1', 'h1'} and occupied_squares == {'g1', 'f1'}:\n",
        "            return Move('e1', 'g1', 'K', is_castle=True, castle_side='kingside')\n",
        "        if vacated_squares == {'e1', 'a1'} and occupied_squares == {'c1', 'd1'}:\n",
        "            return Move('e1', 'c1', 'K', is_castle=True, castle_side='queenside')\n",
        "\n",
        "        # For black\n",
        "        if vacated_squares == {'e8', 'h8'} and occupied_squares == {'g8', 'f8'}:\n",
        "            return Move('e8', 'g8', 'k', is_castle=True, castle_side='kingside')\n",
        "        if vacated_squares == {'e8', 'a8'} and occupied_squares == {'c8', 'd8'}:\n",
        "            return Move('e8', 'c8', 'k', is_castle=True, castle_side='queenside')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Case 2: Simple non-capture or promotion move\n",
        "    # -------------------------------------------------------------------------\n",
        "    if len(vacated) == 1 and len(occupied) == 1:\n",
        "        from_sq, piece = vacated[0]\n",
        "        to_sq, arriving_piece = occupied[0]\n",
        "\n",
        "        if piece.upper() == arriving_piece.upper() or (\n",
        "            piece.upper() == 'P' and arriving_piece.upper() in 'QRBN'\n",
        "        ):\n",
        "            move = Move(from_sq, to_sq, piece)\n",
        "            # Promotion\n",
        "            if piece.upper() == 'P' and arriving_piece.upper() != 'P':\n",
        "                move.promotion_piece = arriving_piece\n",
        "            return move\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Case 3: Capture with two vacated squares and one occupied\n",
        "    # -------------------------------------------------------------------------\n",
        "    if len(vacated) == 2 and len(occupied) == 1:\n",
        "        occ_sq, arriving_piece = occupied[0]\n",
        "        from_sq = None\n",
        "        piece = None\n",
        "        captured = None\n",
        "\n",
        "        for vac_sq, vac_piece in vacated:\n",
        "            if vac_sq == occ_sq:\n",
        "                captured = vac_piece\n",
        "            else:\n",
        "                from_sq = vac_sq\n",
        "                piece = vac_piece\n",
        "\n",
        "        if from_sq and captured:\n",
        "            move = Move(from_sq, occ_sq, piece, captured_piece=captured)\n",
        "            if piece.upper() == 'P' and arriving_piece.upper() != 'P':\n",
        "                move.promotion_piece = arriving_piece\n",
        "            return move\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Case 4: Capture where attacker replaces defender on same square\n",
        "    # -------------------------------------------------------------------------\n",
        "    if len(vacated) == 1 and len(occupied) == 0 and len(changed) == 1:\n",
        "        from_sq, piece = vacated[0]\n",
        "        to_sq, captured, arriving_piece = changed[0]\n",
        "\n",
        "        if piece.upper() == arriving_piece.upper() or (\n",
        "            piece.upper() == 'P' and arriving_piece.upper() in 'QRBN'\n",
        "        ):\n",
        "            move = Move(from_sq, to_sq, piece, captured_piece=captured)\n",
        "            if piece.upper() == 'P' and arriving_piece.upper() != 'P':\n",
        "                move.promotion_piece = arriving_piece\n",
        "            return move\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Case 5: En passant (still fairly strict)\n",
        "    # -------------------------------------------------------------------------\n",
        "    if len(vacated) == 2 and len(occupied) == 1:\n",
        "        occ_sq, arriving_piece = occupied[0]\n",
        "        if arriving_piece.upper() == 'P':\n",
        "            from_sq = None\n",
        "            piece = None\n",
        "            captured_sq = None\n",
        "            captured_piece = None\n",
        "            for vac_sq, vac_piece in vacated:\n",
        "                if vac_piece.upper() == 'P' and from_sq is None:\n",
        "                    from_sq = vac_sq\n",
        "                    piece = vac_piece\n",
        "                elif vac_piece.upper() == 'P':\n",
        "                    captured_sq = vac_sq\n",
        "                    captured_piece = vac_piece\n",
        "\n",
        "            if from_sq and captured_sq:\n",
        "                from_file = ord(from_sq[0])\n",
        "                to_file = ord(occ_sq[0])\n",
        "                cap_file = ord(captured_sq[0])\n",
        "                if abs(from_file - to_file) == 1 and to_file == cap_file:\n",
        "                    return Move(\n",
        "                        from_square=from_sq,\n",
        "                        to_square=occ_sq,\n",
        "                        piece=piece,\n",
        "                        captured_piece=captured_piece,\n",
        "                        is_en_passant=True\n",
        "                    )\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # NEW Case 6: Robust heuristic – pick best single candidate move\n",
        "    # -------------------------------------------------------------------------\n",
        "    candidates: List[Tuple[Move, int]] = []\n",
        "\n",
        "    # Generate all plausible (from_sq -> to_sq) pairs\n",
        "    for from_sq, prev_piece in vacated:\n",
        "        for to_sq, curr_piece in occupied:\n",
        "            # Must be same color & same type (allow pawn -> promoted piece handled earlier)\n",
        "            if prev_piece.isupper() != curr_piece.isupper():\n",
        "                continue\n",
        "            if prev_piece.upper() != curr_piece.upper():\n",
        "                # allow pawn \"changing\" only if to-piece is a promotion target\n",
        "                if not (prev_piece.upper() == 'P' and curr_piece.upper() in 'QRBN'):\n",
        "                    continue\n",
        "\n",
        "            # Basic geometric legality\n",
        "            if not could_piece_move_to(prev_piece, from_sq, to_sq, prev_board):\n",
        "                continue\n",
        "\n",
        "            # Compute how many other squares changed that this move doesn't explain\n",
        "            explained_squares = {from_sq, to_sq}\n",
        "            # For captures: if there was an opposite-color piece on to_sq before, it is explained\n",
        "            prev_on_to = prev_board.get(to_sq)\n",
        "            if prev_on_to and prev_on_to.isupper() != prev_piece.isupper():\n",
        "                explained_squares.add(to_sq)\n",
        "\n",
        "            unexplained = 0\n",
        "            for sq in all_squares:\n",
        "                if sq in explained_squares:\n",
        "                    continue\n",
        "                if prev_board.get(sq) != curr_board.get(sq):\n",
        "                    unexplained += 1\n",
        "\n",
        "            move = Move(from_sq, to_sq, prev_piece)\n",
        "            candidates.append((move, unexplained))\n",
        "\n",
        "    if candidates:\n",
        "        # Choose candidate with minimum unexplained changes\n",
        "        candidates.sort(key=lambda x: x[1])\n",
        "        best_move, best_noise = candidates[0]\n",
        "\n",
        "        # Heuristic threshold: accept if at most 4 other squares changed\n",
        "        # (tune if needed)\n",
        "        if best_noise <= 4:\n",
        "            return best_move\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Fallback: Could not determine move\n",
        "    # -------------------------------------------------------------------------\n",
        "    # (Optional) debug print – you can uncomment while tuning\n",
        "    # print(\"DEBUG move not found\")\n",
        "    # print(\"  vacated:\", vacated)\n",
        "    # print(\"  occupied:\", occupied)\n",
        "    # print(\"  changed:\", changed)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def get_piece_symbol_for_pgn(piece_code: str) -> str:\n",
        "    \"\"\"\n",
        "    Get the PGN piece symbol (uppercase, no symbol for pawns).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    piece_code : str\n",
        "        Single character piece code (e.g., 'K', 'q', 'P').\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        PGN piece symbol (empty string for pawns).\n",
        "    \"\"\"\n",
        "    piece = piece_code.upper()\n",
        "    if piece == 'P':\n",
        "        return ''\n",
        "    return piece\n",
        "\n",
        "\n",
        "def move_to_pgn_notation(\n",
        "    move: Move,\n",
        "    board_before: Dict[str, str]\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Convert a Move object to PGN notation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    move : Move\n",
        "        The move to convert.\n",
        "    board_before : Dict[str, str]\n",
        "        Board state before the move (for disambiguation).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        PGN notation for the move (e.g., 'Nf3', 'exd5', 'O-O').\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> move = Move(from_square='e2', to_square='e4', piece='P')\n",
        "    >>> pgn = move_to_pgn_notation(move, board_before)\n",
        "    >>> print(pgn)  # 'e4'\n",
        "    \"\"\"\n",
        "\n",
        "    # Castling\n",
        "    if move.is_castle:\n",
        "        if move.castle_side == 'kingside':\n",
        "            return 'O-O'\n",
        "        else:\n",
        "            return 'O-O-O'\n",
        "\n",
        "    piece_symbol = get_piece_symbol_for_pgn(move.piece)\n",
        "\n",
        "    # Base notation\n",
        "    notation = piece_symbol\n",
        "\n",
        "    # Check if disambiguation is needed (for pieces other than pawns)\n",
        "    if piece_symbol and piece_symbol != '':\n",
        "        # Find other pieces of same type that could move to the target\n",
        "        need_file = False\n",
        "        need_rank = False\n",
        "\n",
        "        for square, piece in board_before.items():\n",
        "            if piece.upper() == move.piece.upper() and square != move.from_square:\n",
        "                # Check if this piece could also move to the target\n",
        "                # This is a simplified check - full legal move validation\n",
        "                # would require more chess logic\n",
        "                if could_piece_move_to(piece, square, move.to_square, board_before):\n",
        "                    # Need disambiguation\n",
        "                    from_file = move.from_square[0]\n",
        "                    from_rank = move.from_square[1]\n",
        "                    other_file = square[0]\n",
        "                    other_rank = square[1]\n",
        "\n",
        "                    if from_file != other_file:\n",
        "                        need_file = True\n",
        "                    elif from_rank != other_rank:\n",
        "                        need_rank = True\n",
        "                    else:\n",
        "                        need_file = True\n",
        "                        need_rank = True\n",
        "\n",
        "        if need_file:\n",
        "            notation += move.from_square[0]\n",
        "        if need_rank:\n",
        "            notation += move.from_square[1]\n",
        "\n",
        "    # Capture notation\n",
        "    if move.captured_piece or move.is_en_passant:\n",
        "        if move.piece.upper() == 'P' and not piece_symbol:\n",
        "            # Pawn capture includes the file\n",
        "            notation += move.from_square[0]\n",
        "        notation += 'x'\n",
        "\n",
        "    # Destination square\n",
        "    notation += move.to_square\n",
        "\n",
        "    # Promotion\n",
        "    if move.promotion_piece:\n",
        "        notation += '=' + move.promotion_piece.upper()\n",
        "\n",
        "    # En passant (optional, some PGN doesn't include this)\n",
        "    # if move.is_en_passant:\n",
        "    #     notation += ' e.p.'\n",
        "\n",
        "    # Check/checkmate symbols would require full game state\n",
        "    if move.is_checkmate:\n",
        "        notation += '#'\n",
        "    elif move.is_check:\n",
        "        notation += '+'\n",
        "\n",
        "    return notation\n",
        "\n",
        "\n",
        "def could_piece_move_to(\n",
        "    piece: str,\n",
        "    from_square: str,\n",
        "    to_square: str,\n",
        "    board: Dict[str, str]\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Simple check if a piece could potentially move to a target square.\n",
        "\n",
        "    This is a simplified version - doesn't check for blocking pieces,\n",
        "    pins, or other complex chess rules.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    piece : str\n",
        "        Piece code.\n",
        "    from_square : str\n",
        "        Starting square.\n",
        "    to_square : str\n",
        "        Target square.\n",
        "    board : Dict[str, str]\n",
        "        Current board state.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "        True if the move is potentially valid.\n",
        "    \"\"\"\n",
        "    piece_type = piece.upper()\n",
        "\n",
        "    from_file = ord(from_square[0]) - ord('a')\n",
        "    from_rank = int(from_square[1]) - 1\n",
        "    to_file = ord(to_square[0]) - ord('a')\n",
        "    to_rank = int(to_square[1]) - 1\n",
        "\n",
        "    dx = to_file - from_file\n",
        "    dy = to_rank - from_rank\n",
        "\n",
        "    if piece_type == 'N':  # Knight\n",
        "        return (abs(dx), abs(dy)) in [(1, 2), (2, 1)]\n",
        "\n",
        "    elif piece_type == 'B':  # Bishop\n",
        "        return abs(dx) == abs(dy) and dx != 0\n",
        "\n",
        "    elif piece_type == 'R':  # Rook\n",
        "        return (dx == 0 or dy == 0) and (dx != 0 or dy != 0)\n",
        "\n",
        "    elif piece_type == 'Q':  # Queen\n",
        "        return (abs(dx) == abs(dy) or dx == 0 or dy == 0) and (dx != 0 or dy != 0)\n",
        "\n",
        "    elif piece_type == 'K':  # King\n",
        "        return abs(dx) <= 1 and abs(dy) <= 1 and (dx != 0 or dy != 0)\n",
        "\n",
        "    elif piece_type == 'P':  # Pawn\n",
        "        direction = 1 if piece.isupper() else -1  # White moves up, black down\n",
        "        if dx == 0:  # Forward move\n",
        "            return dy == direction or (dy == 2 * direction and\n",
        "                   ((piece.isupper() and from_rank == 1) or\n",
        "                    (piece.islower() and from_rank == 6)))\n",
        "        else:  # Capture\n",
        "            return abs(dx) == 1 and dy == direction\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def append_move_to_pgn(\n",
        "    move: Move,\n",
        "    pgn_so_far: str,\n",
        "    move_number: int,\n",
        "    side_to_move: str,\n",
        "    board_before: Dict[str, str]\n",
        ") -> Tuple[str, int, str]:\n",
        "    \"\"\"\n",
        "    Convert move to PGN and append it to the existing PGN string.\n",
        "\n",
        "    If the game/sequence starts with a black move, format it as\n",
        "    '1... Qh4+' instead of '1. Qh4+'.\n",
        "    \"\"\"\n",
        "    move_notation = move_to_pgn_notation(move, board_before)\n",
        "\n",
        "    if side_to_move == 'white':\n",
        "        # White's move: always 'N. move'\n",
        "        if pgn_so_far:\n",
        "            pgn_so_far += ' '\n",
        "        pgn_so_far += f'{move_number}. {move_notation}'\n",
        "        next_side = 'black'\n",
        "        next_number = move_number\n",
        "\n",
        "    else:\n",
        "        # Black's move\n",
        "        if not pgn_so_far:\n",
        "            # Game (or sequence) starts with Black\n",
        "            pgn_so_far = f'{move_number}... {move_notation}'\n",
        "        else:\n",
        "            # Normal case: black reply to an existing white move\n",
        "            pgn_so_far += f' {move_notation}'\n",
        "        next_side = 'white'\n",
        "        next_number = move_number + 1\n",
        "\n",
        "    return pgn_so_far, next_number, next_side\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZATION HELPERS\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_frame(\n",
        "    title: str,\n",
        "    frame_bgr: np.ndarray,\n",
        "    figsize: Tuple[int, int] = (10, 8)\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Helper to show a BGR frame using matplotlib in Colab.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    title : str\n",
        "        Title for the plot.\n",
        "    frame_bgr : np.ndarray\n",
        "        Frame in BGR format.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_move_overlay(\n",
        "    frame: np.ndarray,\n",
        "    move: Move,\n",
        "    grid_centers: np.ndarray,\n",
        "    square_names: List[str],\n",
        "    board_size: int = DEFAULT_BOARD_SIZE,\n",
        "    figsize: Tuple[int, int] = (10, 10)\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualize a move with arrows on the warped board.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frame : np.ndarray\n",
        "        Warped board image.\n",
        "    move : Move\n",
        "        The move to visualize.\n",
        "    grid_centers : np.ndarray\n",
        "        Grid square centers.\n",
        "    square_names : List[str]\n",
        "        Square names.\n",
        "    board_size : int\n",
        "        Board size.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Get square centers\n",
        "    from_idx = square_names.index(move.from_square)\n",
        "    to_idx = square_names.index(move.to_square)\n",
        "\n",
        "    from_center = grid_centers[from_idx]\n",
        "    to_center = grid_centers[to_idx]\n",
        "\n",
        "    # Draw arrow\n",
        "    ax.annotate(\n",
        "        '',\n",
        "        xy=(to_center[0], to_center[1]),\n",
        "        xytext=(from_center[0], from_center[1]),\n",
        "        arrowprops=dict(\n",
        "            arrowstyle='->,head_width=0.5,head_length=0.3',\n",
        "            color='red',\n",
        "            lw=3\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Highlight squares\n",
        "    square_size = board_size / 8\n",
        "\n",
        "    # From square (red)\n",
        "    rect_from = Rectangle(\n",
        "        (from_center[0] - square_size/2, from_center[1] - square_size/2),\n",
        "        square_size, square_size,\n",
        "        linewidth=3, edgecolor='red', facecolor='red', alpha=0.3\n",
        "    )\n",
        "    ax.add_patch(rect_from)\n",
        "\n",
        "    # To square (green)\n",
        "    rect_to = Rectangle(\n",
        "        (to_center[0] - square_size/2, to_center[1] - square_size/2),\n",
        "        square_size, square_size,\n",
        "        linewidth=3, edgecolor='green', facecolor='green', alpha=0.3\n",
        "    )\n",
        "    ax.add_patch(rect_to)\n",
        "\n",
        "    # Create move description\n",
        "    piece_name = PIECE_NAMES.get(move.piece, move.piece)\n",
        "    move_desc = f\"{piece_name}: {move.from_square} → {move.to_square}\"\n",
        "    if move.captured_piece:\n",
        "        move_desc += f\" (captures {PIECE_NAMES.get(move.captured_piece, move.captured_piece)})\"\n",
        "    if move.is_castle:\n",
        "        move_desc = f\"Castling {move.castle_side}\"\n",
        "    if move.promotion_piece:\n",
        "        move_desc += f\" (promotes to {move.promotion_piece})\"\n",
        "\n",
        "    ax.set_title(f'Move: {move_desc}', fontsize=14)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_board_state(\n",
        "    board_dict: Dict[str, str],\n",
        "    title: str = \"Board State\",\n",
        "    figsize: Tuple[int, int] = (8, 8)\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualize a board state as a text-based diagram.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board_dict : Dict[str, str]\n",
        "        Board state dictionary.\n",
        "    title : str\n",
        "        Title for the diagram.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "\n",
        "    # Draw the board\n",
        "    for row in range(8):\n",
        "        for col in range(8):\n",
        "            # Determine square color\n",
        "            is_light = (row + col) % 2 == 0\n",
        "            color = '#F0D9B5' if is_light else '#B58863'\n",
        "\n",
        "            # Draw square\n",
        "            rect = Rectangle(\n",
        "                (col, 7 - row), 1, 1,\n",
        "                facecolor=color, edgecolor='black', linewidth=0.5\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            # Get piece on this square\n",
        "            file = FILES[col]\n",
        "            rank = str(row + 1)\n",
        "            square = f'{file}{rank}'\n",
        "\n",
        "            if square in board_dict:\n",
        "                piece = board_dict[square]\n",
        "                piece_color = 'white' if piece.isupper() else 'black'\n",
        "\n",
        "                # Use Unicode chess symbols\n",
        "                unicode_pieces = {\n",
        "                    'K': '♔', 'Q': '♕', 'R': '♖', 'B': '♗', 'N': '♘', 'P': '♙',\n",
        "                    'k': '♚', 'q': '♛', 'r': '♜', 'b': '♝', 'n': '♞', 'p': '♟'\n",
        "                }\n",
        "\n",
        "                symbol = unicode_pieces.get(piece, piece)\n",
        "                ax.text(\n",
        "                    col + 0.5, 7 - row + 0.5, symbol,\n",
        "                    fontsize=32, ha='center', va='center',\n",
        "                    color=piece_color\n",
        "                )\n",
        "\n",
        "    # Add file labels\n",
        "    for col, file in enumerate(FILES):\n",
        "        ax.text(col + 0.5, -0.3, file, fontsize=12, ha='center')\n",
        "\n",
        "    # Add rank labels\n",
        "    for row, rank in enumerate(RANKS):\n",
        "        ax.text(-0.3, 7 - row + 0.5, rank, fontsize=12, va='center')\n",
        "\n",
        "    ax.set_xlim(-0.5, 8.5)\n",
        "    ax.set_ylim(-0.5, 8.5)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_summary_visualization(\n",
        "    original_frame: np.ndarray,\n",
        "    warped_board: np.ndarray,\n",
        "    detections: List[PieceDetection],\n",
        "    board_dict: Dict[str, str],\n",
        "    move: Optional[Move],\n",
        "    pgn_so_far: str,\n",
        "    figsize: Tuple[int, int] = (18, 8)\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Create a summary visualization of the current processing state.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    original_frame : np.ndarray\n",
        "        Original video frame.\n",
        "    warped_board : np.ndarray\n",
        "        Warped board image.\n",
        "    detections : List[PieceDetection]\n",
        "        YOLO detections.\n",
        "    board_dict : Dict[str, str]\n",
        "        Current board state.\n",
        "    move : Optional[Move]\n",
        "        Detected move (if any).\n",
        "    pgn_so_far : str\n",
        "        Current PGN string.\n",
        "    figsize : Tuple[int, int]\n",
        "        Figure size.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "\n",
        "    # Original frame with detections\n",
        "    ax1 = fig.add_subplot(1, 3, 1)\n",
        "    frame_annotated = original_frame.copy()\n",
        "    for det in detections:\n",
        "        x1, y1, x2, y2 = det.bbox\n",
        "        color = (255, 255, 0) if det.class_name[0].lower() == 'w' else (255, 0, 255)\n",
        "        cv2.rectangle(frame_annotated, (x1, y1), (x2, y2), color, 2)\n",
        "    ax1.imshow(cv2.cvtColor(frame_annotated, cv2.COLOR_BGR2RGB))\n",
        "    ax1.set_title(f'Original Frame\\n{len(detections)} pieces detected')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Warped board\n",
        "    ax2 = fig.add_subplot(1, 3, 2)\n",
        "    ax2.imshow(cv2.cvtColor(warped_board, cv2.COLOR_BGR2RGB))\n",
        "    ax2.set_title('Warped Board')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # Board state and move info\n",
        "    ax3 = fig.add_subplot(1, 3, 3)\n",
        "    ax3.axis('off')\n",
        "\n",
        "    # Create board text representation\n",
        "    board_text = \"Board State:\\n\"\n",
        "    board_text += \"  a b c d e f g h\\n\"\n",
        "    for rank in range(8, 0, -1):\n",
        "        board_text += f\"{rank} \"\n",
        "        for file in 'abcdefgh':\n",
        "            square = f'{file}{rank}'\n",
        "            piece = board_dict.get(square, '.')\n",
        "            board_text += f\"{piece} \"\n",
        "        board_text += f\"{rank}\\n\"\n",
        "    board_text += \"  a b c d e f g h\\n\"\n",
        "\n",
        "    # Add move info\n",
        "    if move:\n",
        "        board_text += f\"\\nLast Move: {move.from_square} → {move.to_square}\"\n",
        "        if move.captured_piece:\n",
        "            board_text += f\" (capture)\"\n",
        "\n",
        "    # Add PGN\n",
        "    board_text += f\"\\n\\nPGN: {pgn_so_far if pgn_so_far else '(no moves yet)'}\"\n",
        "\n",
        "    ax3.text(0.1, 0.9, board_text, transform=ax3.transAxes,\n",
        "             fontsize=10, family='monospace', verticalalignment='top')\n",
        "    ax3.set_title('Current State')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main_pipeline(\n",
        "    video_path: str,\n",
        "    yolo_model: Any,\n",
        "    unet_model: Any,\n",
        "    ocr_model: Any = None,\n",
        "    vlm_client: Any = None,\n",
        "    output_fps: float = 1.0,\n",
        "    visualize_steps: bool = True,\n",
        "    visualize_every_n_frames: int = 5\n",
        ") -> Tuple[List[BoardState], List[Move], str]:\n",
        "    \"\"\"\n",
        "    Main pipeline for chess move detection from video.\n",
        "\n",
        "    This function orchestrates the entire process:\n",
        "    1. Extract frames from video\n",
        "    2. Filter out frames with hands\n",
        "    3. Detect board corners and compute homography\n",
        "    4. Estimate board rotation\n",
        "    5. Process each frame with YOLO detection\n",
        "    6. Track board state changes\n",
        "    7. Generate PGN notation\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"CHESS MOVE DETECTION PIPELINE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # =========================================================================\n",
        "    # STEP 1: Extract frames from video\n",
        "    # =========================================================================\n",
        "    print(\"\\n[STEP 1] Extracting frames from video...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    frames = extract_frames_from_video(video_path, output_fps=output_fps)\n",
        "\n",
        "    if visualize_steps and len(frames) > 0:\n",
        "        visualize_frame(\"First Extracted Frame\", frames[0])\n",
        "\n",
        "    # =========================================================================\n",
        "    # STEP 2: Filter frames without hands\n",
        "    # =========================================================================\n",
        "    print(\"\\n[STEP 2] Filtering frames (removing frames with hands)...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    clean_frames, clean_indices = filter_frames_no_hands(frames)\n",
        "\n",
        "    if len(clean_frames) == 0:\n",
        "        raise ValueError(\"No clean frames found! All frames contain hands.\")\n",
        "\n",
        "    print(f\"Using {len(clean_frames)} clean frames for analysis\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # STEP 3: Process FIRST clean frame for global parameters\n",
        "    # =========================================================================\n",
        "    print(\"\\n[STEP 3] Computing global board parameters from first clean frame...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    first_frame = clean_frames[0]\n",
        "\n",
        "    # 3.1: Preprocess with Sobel + LoG\n",
        "    print(\"  3.1: Applying Sobel + LoG preprocessing...\")\n",
        "    preprocessed = preprocess_sobel_log(first_frame)\n",
        "\n",
        "    if visualize_steps:\n",
        "        visualize_preprocessing(preprocessed, first_frame)\n",
        "\n",
        "    # 3.2: Detect corners with U-Net\n",
        "    print(\"  3.2: Detecting board corners with U-Net...\")\n",
        "    corners_raw = detect_corners_unet(first_frame, unet_model)\n",
        "    print(f\"       Raw corners detected: {corners_raw}\")\n",
        "\n",
        "    if visualize_steps:\n",
        "        visualize_unet_corners(first_frame, corners_raw, \"U-Net Corner Detection\")\n",
        "\n",
        "    # 3.3: Estimate rotation with OCR + VLM\n",
        "    print(\"  3.3: Estimating board rotation...\")\n",
        "    rotation_deg = estimate_rotation_with_vlm(\n",
        "        first_frame, corners_raw, ocr_model, vlm_client,\n",
        "        visualize=visualize_steps\n",
        "    )\n",
        "    print(f\"       Estimated rotation: {rotation_deg}°\")\n",
        "\n",
        "    # 3.4: Order corners based on rotation\n",
        "    print(\"  3.4: Ordering corners [TL, TR, BR, BL]...\")\n",
        "    corners_ordered = order_corners_tl_tr_br_bl(corners_raw, rotation_deg)\n",
        "    print(f\"       Ordered corners: {corners_ordered}\")\n",
        "\n",
        "    # 3.5: Compute homography\n",
        "    print(\"  3.5: Computing homography matrix...\")\n",
        "    board_size = DEFAULT_BOARD_SIZE\n",
        "    H, dst_points = compute_homography(corners_ordered, board_size)\n",
        "    print(f\"       Homography matrix computed (destination: {board_size}x{board_size})\")\n",
        "\n",
        "    # Warp first frame for visualization\n",
        "    warped_first = warp_board(first_frame, H, board_size)\n",
        "\n",
        "    if visualize_steps:\n",
        "        visualize_frame(\"Warped Board (First Frame)\", warped_first)\n",
        "\n",
        "    # 3.6: Compute board grid\n",
        "    print(\"  3.6: Computing board grid centers and square names...\")\n",
        "    grid_centers, square_names = compute_board_grid(board_size, 8, rotation_deg)\n",
        "    print(f\"       Grid computed: 64 squares from {square_names[0]} to {square_names[-1]}\")\n",
        "\n",
        "    if visualize_steps:\n",
        "        visualize_board_grid(warped_first, grid_centers, square_names, board_size)\n",
        "\n",
        "    # Store global parameters\n",
        "    global_params = GlobalBoardParameters(\n",
        "        rotation_degrees=rotation_deg,\n",
        "        corners_ordered=corners_ordered,\n",
        "        homography_matrix=H,\n",
        "        board_size=board_size,\n",
        "        grid_centers=grid_centers,\n",
        "        square_names=square_names\n",
        "    )\n",
        "\n",
        "    # =========================================================================\n",
        "    # STEP 4: Process each clean frame\n",
        "    # =========================================================================\n",
        "    print(\"\\n[STEP 4] Processing each clean frame...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    board_states: List[BoardState] = []\n",
        "    moves: List[Move] = []\n",
        "    pgn = \"\"\n",
        "    move_number = 1\n",
        "    side_to_move = 'white'\n",
        "\n",
        "    # NEW: last reliable board (ignores noisy frames)\n",
        "    trusted_board: Optional[Dict[str, str]] = None\n",
        "\n",
        "    for i, (frame, orig_idx) in enumerate(zip(clean_frames, clean_indices)):\n",
        "        print(f\"  Processing frame {i+1}/{len(clean_frames)} (original index: {orig_idx})...\")\n",
        "\n",
        "        # 4.1: Optional preprocessing just for visualization\n",
        "        preprocessed = preprocess_sobel_log(frame)\n",
        "        if visualize_steps and i % visualize_every_n_frames == 0:\n",
        "            visualize_preprocessing(preprocessed, frame)\n",
        "\n",
        "        # 4.2: Run YOLO detection on ORIGINAL frame\n",
        "        detections = detect_pieces_yolo(\n",
        "            frame,\n",
        "            yolo_model,\n",
        "            conf_thres=0.3,\n",
        "            iou_thres=0.45,\n",
        "            rotation_deg=rotation_deg\n",
        "        )\n",
        "        print(f\"       Detected {len(detections)} pieces\")\n",
        "\n",
        "        # 4.3 & 4.4: Project piece centers using homography\n",
        "        projected_centers = None\n",
        "        piece_types: List[str] = []\n",
        "\n",
        "        if detections:\n",
        "            piece_centers = np.array([det.center for det in detections])\n",
        "            projected_centers = project_points_with_homography(piece_centers, H)\n",
        "\n",
        "            # Update detections with projected centers\n",
        "            for det, proj_center in zip(detections, projected_centers):\n",
        "                det.projected_center = tuple(proj_center)\n",
        "\n",
        "            # Get piece types (convert YOLO class names to piece codes)\n",
        "            for det in detections:\n",
        "                piece_code = PIECE_SYMBOLS.get(det.class_name.lower(), '?')\n",
        "                piece_types.append(piece_code)\n",
        "\n",
        "            # 4.5: Assign pieces to squares\n",
        "            board_dict = assign_pieces_to_squares(\n",
        "                projected_centers, piece_types, grid_centers, square_names\n",
        "            )\n",
        "        else:\n",
        "            board_dict = {}\n",
        "\n",
        "        # 4.6: Build board state\n",
        "        board_state = BoardState(\n",
        "            frame_index=orig_idx,\n",
        "            pieces=board_dict,\n",
        "            detections=detections\n",
        "        )\n",
        "        board_states.append(board_state)\n",
        "\n",
        "        # 4.7: Detect move using TRUSTED board (not just last frame)\n",
        "        detected_move: Optional[Move] = None\n",
        "\n",
        "        if trusted_board is None:\n",
        "            # First frame: initialize baseline\n",
        "            trusted_board = board_dict.copy()\n",
        "        else:\n",
        "            # Compare with last reliable board\n",
        "            detected_move = detect_move_from_states(trusted_board, board_dict)\n",
        "\n",
        "            if detected_move:\n",
        "                # Determine who moved first in the sequence\n",
        "                if not pgn:\n",
        "                    side_to_move = 'black' if detected_move.piece.islower() else 'white'\n",
        "\n",
        "                # Check if this move gives check\n",
        "                moving_is_white = detected_move.piece.isupper()\n",
        "                enemy_king_code = 'k' if moving_is_white else 'K'\n",
        "                enemy_king_square = None\n",
        "                for sq, pc in board_dict.items():\n",
        "                    if pc == enemy_king_code:\n",
        "                        enemy_king_square = sq\n",
        "                        break\n",
        "\n",
        "                if enemy_king_square is not None:\n",
        "                    if is_square_attacked(board_dict, enemy_king_square, by_white=moving_is_white):\n",
        "                        detected_move.is_check = True\n",
        "\n",
        "                moves.append(detected_move)\n",
        "                check_suffix = \"+\" if detected_move.is_check else \"\"\n",
        "                print(\n",
        "                    f\"       Move detected (trusted): \"\n",
        "                    f\"{detected_move.from_square} → {detected_move.to_square}{check_suffix}\"\n",
        "                )\n",
        "\n",
        "                # Use TRUSTED board as \"board_before\" for PGN\n",
        "                pgn, move_number, side_to_move = append_move_to_pgn(\n",
        "                    detected_move, pgn, move_number, side_to_move, trusted_board\n",
        "                )\n",
        "\n",
        "                # Update reliable baseline\n",
        "                trusted_board = board_dict.copy()\n",
        "\n",
        "            else:\n",
        "                # No clear move: decide whether frame is just minor jitter or trash\n",
        "                diff_squares = [\n",
        "                    sq for sq in set(trusted_board.keys()) | set(board_dict.keys())\n",
        "                    if trusted_board.get(sq) != board_dict.get(sq)\n",
        "                ]\n",
        "                num_diff = len(diff_squares)\n",
        "\n",
        "                if num_diff <= 2:\n",
        "                    # Small differences (e.g. one pawn flicker) – accept as updated baseline\n",
        "                    print(\n",
        "                        f\"       No clear move, but only {num_diff} squares differ \"\n",
        "                        f\"→ minor noise, updating trusted board.\"\n",
        "                    )\n",
        "                    trusted_board = board_dict.copy()\n",
        "                else:\n",
        "                    # Many differences – likely bad YOLO frame\n",
        "                    print(\n",
        "                        f\"       No reliable move and {num_diff} squares differ \"\n",
        "                        f\"→ IGNORING this frame as noisy.\"\n",
        "                    )\n",
        "\n",
        "        # Visualization (every N frames or when move detected)\n",
        "        should_visualize = (\n",
        "            visualize_steps and\n",
        "            ((i % visualize_every_n_frames == 0) or detected_move is not None)\n",
        "        )\n",
        "\n",
        "        if should_visualize:\n",
        "            warped_frame = warp_board(frame, H, board_size)\n",
        "\n",
        "            # Show YOLO detections\n",
        "            visualize_yolo_detections(\n",
        "                frame, detections,\n",
        "                f\"YOLO Detections - Frame {orig_idx}\"\n",
        "            )\n",
        "\n",
        "            # Show piece assignments\n",
        "            if detections and projected_centers is not None:\n",
        "                visualize_piece_assignments(\n",
        "                    warped_frame, projected_centers, piece_types,\n",
        "                    grid_centers, square_names, board_dict\n",
        "                )\n",
        "\n",
        "            # Show move overlay if move detected\n",
        "            if detected_move:\n",
        "                visualize_move_overlay(\n",
        "                    warped_frame, detected_move,\n",
        "                    grid_centers, square_names, board_size\n",
        "                )\n",
        "\n",
        "            # Show summary\n",
        "            create_summary_visualization(\n",
        "                frame, warped_frame, detections, board_dict, detected_move, pgn\n",
        "            )\n",
        "\n",
        "    # =========================================================================\n",
        "    # STEP 5: Final output\n",
        "    # =========================================================================\n",
        "    print(\"\\n[STEP 5] Final Results\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Total frames processed: {len(clean_frames)}\")\n",
        "    print(f\"Total board states recorded: {len(board_states)}\")\n",
        "    print(f\"Total moves detected: {len(moves)}\")\n",
        "    print(f\"\\nPGN Output:\")\n",
        "    print(f\"  {pgn if pgn else '(no moves detected)'}\")\n",
        "\n",
        "    # Final board visualization\n",
        "    if visualize_steps and board_states:\n",
        "        final_board = board_states[-1].pieces\n",
        "        visualize_board_state(final_board, \"Final Board Position\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"PIPELINE COMPLETE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    return board_states, moves, pgn\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS FOR COLAB\n",
        "# ============================================================================\n",
        "\n",
        "def setup_colab_environment():\n",
        "    \"\"\"\n",
        "    Setup function for Google Colab environment.\n",
        "    Installs required packages and sets up display.\n",
        "    \"\"\"\n",
        "    print(\"Setting up Colab environment...\")\n",
        "\n",
        "    # Import display utilities\n",
        "    try:\n",
        "        from google.colab.patches import cv2_imshow\n",
        "        print(\"Google Colab detected - using cv2_imshow\")\n",
        "    except ImportError:\n",
        "        print(\"Not running in Colab - using matplotlib for display\")\n",
        "\n",
        "    # Set matplotlib to inline mode\n",
        "    try:\n",
        "        from IPython import get_ipython\n",
        "        get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"Environment setup complete!\")\n",
        "\n",
        "\n",
        "def load_sample_video(url: str, output_path: str = \"chess_game.mp4\") -> str:\n",
        "    \"\"\"\n",
        "    Download a sample video from URL for testing.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : str\n",
        "        URL of the video to download.\n",
        "    output_path : str\n",
        "        Local path to save the video.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Path to the downloaded video.\n",
        "    \"\"\"\n",
        "    import urllib.request\n",
        "\n",
        "    print(f\"Downloading video from {url}...\")\n",
        "    urllib.request.urlretrieve(url, output_path)\n",
        "    print(f\"Video saved to {output_path}\")\n",
        "\n",
        "    return output_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install OCR\n",
        "!pip install easyocr\n",
        "!pip install -q google-genai\n",
        "!pip install -U google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToHrta3TaTCp",
        "outputId": "de5ceb43-f9ca-49b0-8837-e9df3c9d8002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.24.0+cu126)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.16.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from easyocr) (11.3.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.6.7)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from easyocr) (6.0.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.1.2)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.4.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.5.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->easyocr) (3.0.3)\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.55.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.12.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "# @title Set Gemini API Key\n",
        "GEMINI_API_KEY = \"AIzaSyC0I-S6l-zf2ZQckDQsMaOVF9rznDD2Ahw\"  # <-- put real key here\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "\n",
        "import google.genai as genai\n",
        "from google.genai import types as genai_types\n",
        "\n",
        "\n",
        "class GeminiVLMClient:\n",
        "    \"\"\"\n",
        "    Simple wrapper so the pipeline can call:\n",
        "        vlm_client.analyze(image_base64, prompt) -> text answer\n",
        "\n",
        "    Uses Gemini 1.5 Flash by default (good + cheap + fast).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: str,\n",
        "        model_name: str = \"gemini-2.5-flash\",\n",
        "    ):\n",
        "        if not api_key:\n",
        "            raise ValueError(\"Gemini API key is required\")\n",
        "\n",
        "        self.client = genai.Client(api_key=api_key)\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def analyze(self, image: str, prompt: str) -> str:\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        image : str\n",
        "            Base64-encoded JPEG bytes (as produced in query_vlm_for_rotation).\n",
        "        prompt : str\n",
        "            Text instruction.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Model's text response.\n",
        "        \"\"\"\n",
        "        # Decode base64 to raw bytes\n",
        "        img_bytes = base64.b64decode(image)\n",
        "\n",
        "        # Build the content for the Gemini multimodal call\n",
        "        response = self.client.models.generate_content(\n",
        "            model=self.model_name,\n",
        "            contents=[\n",
        "                genai_types.Part.from_bytes(\n",
        "                    data=img_bytes,\n",
        "                    mime_type=\"image/jpeg\"\n",
        "                ),\n",
        "                prompt,\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        # Extract text (Gemini returns a structured object)\n",
        "        try:\n",
        "            return response.text.strip()\n",
        "        except Exception:\n",
        "            return str(response)\n"
      ],
      "metadata": {
        "id": "X8WSrOok35oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Here"
      ],
      "metadata": {
        "id": "VajtdnInEdGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup environment (optional helper)\n",
        "setup_colab_environment()\n",
        "\n",
        "# 2. Load your models\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# YOLO model\n",
        "yolo_model = YOLO(\"/content/drive/MyDrive/yolo/best.pt\")\n",
        "\n",
        "# U-Net model (example if PyTorch)\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Dig_Image/U-Net/U-Net Best.pt\"\n",
        "\n",
        "# Choose device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# # Instantiate and load model\n",
        "unet_model = load_unet(MODEL_PATH)\n",
        "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "unet_model.load_state_dict(state_dict)\n",
        "unet_model.eval()\n",
        "\n",
        "# # 3. Optional: OCR + VLM\n",
        "import easyocr\n",
        "ocr_model = easyocr.Reader(['en'])   # or your OCR\n",
        "\n",
        "vlm_client = GeminiVLMClient(\n",
        "    api_key=os.environ.get(\"GOOGLE_API_KEY\", GEMINI_API_KEY)  # or just pass the key\n",
        ")  # or your actual VLM client wrapper\n",
        "\n",
        "# 4. Run pipeline\n",
        "video_path = \"/content/drive/MyDrive/Chess Detection Competition/test_videos/8_Move_student.mp4\"\n",
        "# video_path = \"/content/drive/MyDrive/Chess Detection Competition/test_videos/2_Move_rotate_student.mp4\"\n",
        "\n",
        "board_states, moves, pgn = main_pipeline(\n",
        "    video_path=video_path,\n",
        "    yolo_model=yolo_model,\n",
        "    unet_model=unet_model,\n",
        "    ocr_model=ocr_model,\n",
        "    vlm_client=vlm_client,          # or None if you temporarily disable\n",
        "    output_fps=1.0,                 # lower for faster processing\n",
        "    visualize_steps=True,\n",
        "    visualize_every_n_frames=5\n",
        ")\n",
        "\n",
        "print(\"Final PGN:\")\n",
        "print(pgn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mjL8tuOvIQjm",
        "outputId": "2e8f4a4a-acfb-4bbb-fc3b-21703ed76442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'setup_colab_environment' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-735849633.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Setup environment (optional helper)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msetup_colab_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 2. Load your models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'setup_colab_environment' is not defined"
          ]
        }
      ]
    }
  ]
}